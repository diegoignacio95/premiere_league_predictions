{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Match Prediction Model v1\n",
    "\n",
    "This notebook develops the first machine learning model for football match outcome prediction using the master dataset.\n",
    "\n",
    "## Objectives:\n",
    "- Load the master dataset with comprehensive match features\n",
    "- Perform exploratory data analysis and feature engineering\n",
    "- Build and evaluate prediction models\n",
    "- Compare different algorithms and approaches\n",
    "- Generate predictions and model insights\n",
    "\n",
    "## Dataset Features:\n",
    "- Match statistics (possession, shots, passes, etc.)\n",
    "- Team wage information and squad details\n",
    "- Historical form metrics (rolling 5-match averages)\n",
    "- Rest days and contextual match information\n",
    "- Both team and opponent perspectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50230\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:61: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif, f_classif\n",
    "from scipy.stats import pearsonr,ranksums\n",
    "\n",
    "# Machine Learning libraries\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\n",
      "Masters data: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\masters\n",
      "Models directory: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\models\\premier_league\n"
     ]
    }
   ],
   "source": [
    "# Set up paths\n",
    "project_root = Path().resolve().parent.parent.parent\n",
    "data_masters = project_root / 'data' / 'prod' / 'processed' / 'masters'\n",
    "models_dir = project_root / 'models' / 'premier_league'\n",
    "\n",
    "# Create models directory if it doesn't exist\n",
    "models_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Masters data: {data_masters}\")\n",
    "print(f\"Models directory: {models_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "\n",
    "Load the master dataset created in the data engineering phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Dataset loaded successfully\n",
      "  Shape: (5711, 258)\n",
      "  Memory usage: 15.7 MB\n"
     ]
    }
   ],
   "source": [
    "# Load master dataset (prefer parquet for efficiency)\n",
    "dataset_file = data_masters / 'match_stats_master_complete_v1.parquet'\n",
    "\n",
    "if dataset_file.exists():\n",
    "    df = pd.read_parquet(dataset_file)\n",
    "    print(f\"✓ Dataset loaded successfully\")\n",
    "    print(f\"  Shape: {df.shape}\")\n",
    "    print(f\"  Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.1f} MB\")\n",
    "else:\n",
    "    print(\"✗ Master dataset not found. Please run master_creation_v1.ipynb first.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Dropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    'date',\n",
    "    'comp',\n",
    "    'round',\n",
    "    'season',\n",
    "    'team_id',\n",
    "    'full_match_report_url',\n",
    "    'team_name',\n",
    "    'opponent',\n",
    "    'opponent_id',\n",
    "    \n",
    "]\n",
    "\n",
    "match_cols = [\n",
    "    'referee',\n",
    "    'start_time',\n",
    "    'dayofweek'\n",
    "]\n",
    "\n",
    "target_cols = [\n",
    "    'result',\n",
    "]\n",
    "\n",
    "stats_team_A = [\n",
    "    'venue',\n",
    "    'Aerials Won_favor_form_avg',\n",
    "    'Aerials Won_favor_form_sum',\n",
    "    'Clearances_favor_form_avg',\n",
    "    'Clearances_favor_form_sum',\n",
    "    'Corners_favor_form_avg',\n",
    "    'Corners_favor_form_sum',\n",
    "    'Crosses_favor_form_avg',\n",
    "    'Crosses_favor_form_sum',\n",
    "    'Fouls_favor_form_avg',\n",
    "    'Fouls_favor_form_sum',\n",
    "    'Goal Kicks_favor_form_avg',\n",
    "    'Goal Kicks_favor_form_sum',\n",
    "    'Interceptions_favor_form_avg',\n",
    "    'Interceptions_favor_form_sum',\n",
    "    'Long Balls_favor_form_avg',\n",
    "    'Long Balls_favor_form_sum',\n",
    "    'Offsides_favor_form_avg',\n",
    "    'Offsides_favor_form_sum',\n",
    "    'Passing Accuracy_favor_form_avg',\n",
    "    'Passing Accuracy_favor_form_sum',\n",
    "    'Possession_favor_form_avg',\n",
    "    'Possession_favor_form_sum',\n",
    "    'Saves_favor_form_avg',\n",
    "    'Saves_favor_form_sum',\n",
    "    'Shots on Target_favor_form_avg',\n",
    "    'Shots on Target_favor_form_sum',\n",
    "    'Tackles_favor_form_avg',\n",
    "    'Tackles_favor_form_sum',\n",
    "    'Throw Ins_favor_form_avg',\n",
    "    'Throw Ins_favor_form_sum',\n",
    "    'Touches_favor_form_avg',\n",
    "    'Touches_favor_form_sum',\n",
    "    'Aerials Won_against_form_avg',\n",
    "    'Aerials Won_against_form_sum',\n",
    "    'Clearances_against_form_avg',\n",
    "    'Clearances_against_form_sum',\n",
    "    'Corners_against_form_avg',\n",
    "    'Corners_against_form_sum',\n",
    "    'Crosses_against_form_avg',\n",
    "    'Crosses_against_form_sum',\n",
    "    'Fouls_against_form_avg',\n",
    "    'Fouls_against_form_sum',\n",
    "    'Goal Kicks_against_form_avg',\n",
    "    'Goal Kicks_against_form_sum',\n",
    "    'Interceptions_against_form_avg',\n",
    "    'Interceptions_against_form_sum',\n",
    "    'Long Balls_against_form_avg',\n",
    "    'Long Balls_against_form_sum',\n",
    "    'Offsides_against_form_avg',\n",
    "    'Offsides_against_form_sum',\n",
    "    'Passing Accuracy_against_form_avg',\n",
    "    'Passing Accuracy_against_form_sum',\n",
    "    'Possession_against_form_avg',\n",
    "    'Possession_against_form_sum',\n",
    "    'Saves_against_form_avg',\n",
    "    'Saves_against_form_sum',\n",
    "    'Shots on Target_against_form_avg',\n",
    "    'Shots on Target_against_form_sum',\n",
    "    'Tackles_against_form_avg',\n",
    "    'Tackles_against_form_sum',\n",
    "    'Throw Ins_against_form_avg',\n",
    "    'Throw Ins_against_form_sum',\n",
    "    'Touches_against_form_avg',\n",
    "    'Touches_against_form_sum',\n",
    "    'points_form_avg',\n",
    "    'points_form_sum',\n",
    "    'rest_days',\n",
    "    'rest_days_form_avg',\n",
    "    'rest_days_form_sum',\n",
    "    'xg_for_form_avg',\n",
    "    'xg_for_form_sum',\n",
    "    'xg_against_form_avg',\n",
    "    'xg_against_form_sum',\n",
    "    'goals_for_form_avg',\n",
    "    'goals_for_form_sum',\n",
    "    'goals_against_form_avg',\n",
    "    'goals_against_form_sum'\n",
    "]\n",
    "\n",
    "columnas_team_A_validacion = [\n",
    "    'Aerials Won_favor',\n",
    "    'Clearances_favor',\n",
    "    'Corners_favor',\n",
    "    'Crosses_favor',\n",
    "    'Fouls_favor',\n",
    "    'Goal Kicks_favor',\n",
    "    'Interceptions_favor',\n",
    "    'Long Balls_favor',\n",
    "    'Offsides_favor',\n",
    "    'Passing Accuracy_favor',\n",
    "    'Possession_favor',\n",
    "    'Saves_favor',\n",
    "    'Shots on Target_favor',\n",
    "    'Tackles_favor',\n",
    "    'Throw Ins_favor',\n",
    "    'Touches_favor',\n",
    "    'Aerials Won_against',\n",
    "    'Clearances_against',\n",
    "    'Corners_against',\n",
    "    'Crosses_against',\n",
    "    'Fouls_against',\n",
    "    'Goal Kicks_against',\n",
    "    'Interceptions_against',\n",
    "    'Long Balls_against',\n",
    "    'Offsides_against',\n",
    "    'Passing Accuracy_against',\n",
    "    'Possession_against',\n",
    "    'Saves_against',\n",
    "    'Shots on Target_against',\n",
    "    'Tackles_against',\n",
    "    'Throw Ins_against',\n",
    "    'Touches_against',\n",
    "    'points',\n",
    "    'xg_for',\n",
    "    'xg_against',\n",
    "    'goals_for',\n",
    "    'goals_against'\n",
    "]\n",
    "\n",
    "players_team_A = [\n",
    "    'age_mean',\n",
    "    'squad_size',\n",
    "    'age_max',\n",
    "    'age_min',\n",
    "    'avg_wage_dollars',\n",
    "    'total_wage_bill_dollars',\n",
    "    'max_wage_dollars',\n",
    "    'min_wage_dollars'\n",
    " \n",
    "]\n",
    "\n",
    "stats_team_B = [\n",
    "    'Aerials Won_favor_opponent_form_avg',\n",
    "    'Aerials Won_favor_opponent_form_sum',\n",
    "    'Clearances_favor_opponent_form_avg',\n",
    "    'Clearances_favor_opponent_form_sum',\n",
    "    'Corners_favor_opponent_form_avg',\n",
    "    'Corners_favor_opponent_form_sum',\n",
    "    'Crosses_favor_opponent_form_avg',\n",
    "    'Crosses_favor_opponent_form_sum',\n",
    "    'Fouls_favor_opponent_form_avg',\n",
    "    'Fouls_favor_opponent_form_sum',\n",
    "    'Goal Kicks_favor_opponent_form_avg',\n",
    "    'Goal Kicks_favor_opponent_form_sum',\n",
    "    'Interceptions_favor_opponent_form_avg',\n",
    "    'Interceptions_favor_opponent_form_sum',\n",
    "    'Long Balls_favor_opponent_form_avg',\n",
    "    'Long Balls_favor_opponent_form_sum',\n",
    "    'Offsides_favor_opponent_form_avg',\n",
    "    'Offsides_favor_opponent_form_sum',\n",
    "    'Passing Accuracy_favor_opponent_form_avg',\n",
    "    'Passing Accuracy_favor_opponent_form_sum',\n",
    "    'Possession_favor_opponent_form_avg',\n",
    "    'Possession_favor_opponent_form_sum',\n",
    "    'Saves_favor_opponent_form_avg',\n",
    "    'Saves_favor_opponent_form_sum',\n",
    "    'Shots on Target_favor_opponent_form_avg',\n",
    "    'Shots on Target_favor_opponent_form_sum',\n",
    "    'Tackles_favor_opponent_form_avg',\n",
    "    'Tackles_favor_opponent_form_sum',\n",
    "    'Throw Ins_favor_opponent_form_avg',\n",
    "    'Throw Ins_favor_opponent_form_sum',\n",
    "    'Touches_favor_opponent_form_avg',\n",
    "    'Touches_favor_opponent_form_sum',\n",
    "    'Aerials Won_against_opponent_form_avg',\n",
    "    'Aerials Won_against_opponent_form_sum',\n",
    "    'Clearances_against_opponent_form_avg',\n",
    "    'Clearances_against_opponent_form_sum',\n",
    "    'Corners_against_opponent_form_avg',\n",
    "    'Corners_against_opponent_form_sum',\n",
    "    'Crosses_against_opponent_form_avg',\n",
    "    'Crosses_against_opponent_form_sum',\n",
    "    'Fouls_against_opponent_form_avg',\n",
    "    'Fouls_against_opponent_form_sum',\n",
    "    'Goal Kicks_against_opponent_form_avg',\n",
    "    'Goal Kicks_against_opponent_form_sum',\n",
    "    'Interceptions_against_opponent_form_avg',\n",
    "    'Interceptions_against_opponent_form_sum',\n",
    "    'Long Balls_against_opponent_form_avg',\n",
    "    'Long Balls_against_opponent_form_sum',\n",
    "    'Offsides_against_opponent_form_avg',\n",
    "    'Offsides_against_opponent_form_sum',\n",
    "    'Passing Accuracy_against_opponent_form_avg',\n",
    "    'Passing Accuracy_against_opponent_form_sum',\n",
    "    'Possession_against_opponent_form_avg',\n",
    "    'Possession_against_opponent_form_sum',\n",
    "    'Saves_against_opponent_form_avg',\n",
    "    'Saves_against_opponent_form_sum',\n",
    "    'Shots on Target_against_opponent_form_avg',\n",
    "    'Shots on Target_against_opponent_form_sum',\n",
    "    'Tackles_against_opponent_form_avg',\n",
    "    'Tackles_against_opponent_form_sum',\n",
    "    'Throw Ins_against_opponent_form_avg',\n",
    "    'Throw Ins_against_opponent_form_sum',\n",
    "    'Touches_against_opponent_form_avg',\n",
    "    'Touches_against_opponent_form_sum',\n",
    "    'points_opponent_form_avg',\n",
    "    'points_opponent_form_sum',\n",
    "    'rest_days_opponent',\n",
    "    'rest_days_opponent_form_avg',\n",
    "    'rest_days_opponent_form_sum',\n",
    "    'xg_for_opponent_form_avg',\n",
    "    'xg_for_opponent_form_sum',\n",
    "    'xg_against_opponent_form_avg',\n",
    "    'xg_against_opponent_form_sum',\n",
    "    'goals_for_opponent_form_avg',\n",
    "    'goals_for_opponent_form_sum',\n",
    "    'goals_against_opponent_form_avg',\n",
    "    'goals_against_opponent_form_sum'\n",
    "]\n",
    "\n",
    "columnas_team_B_validacion = [\n",
    "    'Aerials Won_favor_opponent',\n",
    "    'Clearances_favor_opponent',\n",
    "    'Corners_favor_opponent',\n",
    "    'Crosses_favor_opponent',\n",
    "    'Fouls_favor_opponent',\n",
    "    'Goal Kicks_favor_opponent',\n",
    "    'Interceptions_favor_opponent',\n",
    "    'Long Balls_favor_opponent',\n",
    "    'Offsides_favor_opponent',\n",
    "    'Passing Accuracy_favor_opponent',\n",
    "    'Possession_favor_opponent',\n",
    "    'Saves_favor_opponent',\n",
    "    'Shots on Target_favor_opponent',\n",
    "    'Tackles_favor_opponent',\n",
    "    'Throw Ins_favor_opponent',\n",
    "    'Touches_favor_opponent',\n",
    "    'Aerials Won_against_opponent',\n",
    "    'Clearances_against_opponent',\n",
    "    'Corners_against_opponent',\n",
    "    'Crosses_against_opponent',\n",
    "    'Fouls_against_opponent',\n",
    "    'Goal Kicks_against_opponent',\n",
    "    'Interceptions_against_opponent',\n",
    "    'Long Balls_against_opponent',\n",
    "    'Offsides_against_opponent',\n",
    "    'Passing Accuracy_against_opponent',\n",
    "    'Possession_against_opponent',\n",
    "    'Saves_against_opponent',\n",
    "    'Shots on Target_against_opponent',\n",
    "    'Tackles_against_opponent',\n",
    "    'Throw Ins_against_opponent',\n",
    "    'Touches_against_opponent',\n",
    "    'points_opponent',\n",
    "    'xg_for_opponent',\n",
    "    'xg_against_opponent',\n",
    "    'goals_for_opponent',\n",
    "    'goals_against_opponent'\n",
    "]\n",
    "\n",
    "players_team_B = [\n",
    "    'opp_age_mean',\n",
    "    'opp_squad_size',\n",
    "    'opp_age_max',\n",
    "    'opp_age_min',\n",
    "    'opp_avg_wage_dollars',\n",
    "    'opp_total_wage_bill_dollars',\n",
    "    'opp_max_wage_dollars',\n",
    "    'opp_min_wage_dollars'\n",
    "]\n",
    "\n",
    "cols_drop = columnas_team_A_validacion + columnas_team_B_validacion\n",
    "\n",
    "df.drop(cols_drop,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering & Data Preparation\n",
    "\n",
    "Analyze the dataset structure and target variable distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Overview:\n",
      "  Rows: 5,711\n",
      "  Columns: 192\n",
      "  Date range: 2019-08-04 00:00:00 to 2025-05-28 00:00:00\n",
      "  Seasons: ['2019-2020', '2020-2021', '2021-2022', '2022-2023', '2023-2024', '2024-2025']\n",
      "  Teams: 27 unique teams\n",
      "\n",
      "Target Variable (Result) Distribution:\n",
      "  W: 2,406 (42.1%)\n",
      "  D: 1,257 (22.0%)\n",
      "  L: 2,048 (35.9%)\n",
      "\n",
      "Columns with missing values (top 10):\n",
      "  rest_days_opponent_form_sum: 817 (14.3%)\n",
      "  rest_days_opponent_form_avg: 817 (14.3%)\n",
      "  xg_against_opponent_form_sum: 796 (13.9%)\n",
      "  xg_against_opponent_form_avg: 796 (13.9%)\n",
      "  xg_for_opponent_form_sum: 796 (13.9%)\n",
      "  xg_for_opponent_form_avg: 796 (13.9%)\n",
      "  Saves_favor_opponent_form_avg: 794 (13.9%)\n",
      "  Long Balls_favor_opponent_form_sum: 794 (13.9%)\n",
      "  Offsides_favor_opponent_form_avg: 794 (13.9%)\n",
      "  Offsides_favor_opponent_form_sum: 794 (13.9%)\n"
     ]
    }
   ],
   "source": [
    "cols_add_A = [\n",
    " 'age_mean',\n",
    " 'squad_size',\n",
    " 'age_max',\n",
    " 'age_min',\n",
    " 'avg_wage_dollars',\n",
    " 'total_wage_bill_dollars',\n",
    " 'max_wage_dollars',\n",
    " 'min_wage_dollars'\n",
    "]\n",
    "\n",
    "cols_add_B = [\n",
    "'opp_age_mean',\n",
    " 'opp_squad_size',\n",
    " 'opp_age_max',\n",
    " 'opp_age_min',\n",
    " 'opp_avg_wage_dollars',\n",
    " 'opp_total_wage_bill_dollars',\n",
    " 'opp_max_wage_dollars',\n",
    " 'opp_min_wage_dollars' \n",
    "]\n",
    "\n",
    "for columna in range(len(cols_add_A)):\n",
    "    df[cols_add_A[columna] + '_diff'] = df[cols_add_A[columna]] - df[cols_add_B[columna]]\n",
    "\n",
    "if df is not None:\n",
    "    # Basic dataset info\n",
    "    print(\"Dataset Overview:\")\n",
    "    print(f\"  Rows: {len(df):,}\")\n",
    "    print(f\"  Columns: {len(df.columns):,}\")\n",
    "    print(f\"  Date range: {df['date'].min()} to {df['date'].max()}\")\n",
    "    print(f\"  Seasons: {sorted(df['season'].unique())}\")\n",
    "    print(f\"  Teams: {len(df['team_id'].unique())} unique teams\")\n",
    "    \n",
    "    # Target variable distribution\n",
    "    print(\"\\nTarget Variable (Result) Distribution:\")\n",
    "    result_counts = df['result'].value_counts()\n",
    "    result_pct = df['result'].value_counts(normalize=True) * 100\n",
    "    \n",
    "    for result in ['W', 'D', 'L']:\n",
    "        if result in result_counts:\n",
    "            print(f\"  {result}: {result_counts[result]:,} ({result_pct[result]:.1f}%)\")\n",
    "    \n",
    "    # Missing values summary\n",
    "    missing_summary = df.isnull().sum().sort_values(ascending=False)\n",
    "    missing_pct = (missing_summary / len(df) * 100).round(1)\n",
    "    \n",
    "    print(f\"\\nColumns with missing values (top 10):\")\n",
    "    for col, missing in missing_summary.head(10).items():\n",
    "        if missing > 0:\n",
    "            print(f\"  {col}: {missing:,} ({missing_pct[col]}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['dayofweek'].map({\n",
    "      'Mon': 'midweek',    \n",
    "      'Tue': 'midweek',    \n",
    "      'Wed': 'midweek',    \n",
    "      'Thu': 'midweek',    \n",
    "      'Fri': 'Fri',    \n",
    "      'Sat': 'Sat',    \n",
    "      'Sun': 'Sun'\n",
    "})\n",
    "\n",
    "dummies = pd.get_dummies(\n",
    "    df['dayofweek'],\n",
    "    drop_first=False,\n",
    "    dtype=int\n",
    ")\n",
    "\n",
    "df.drop('dayofweek', axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([df, dummies], axis=1)\n",
    "\n",
    "df['venue'] = df['venue'].map({\n",
    "    'Away': 0,\n",
    "    'Home': 1,\n",
    "    'Neutral': 0\n",
    "})\n",
    "\n",
    "df['result'] = df['result'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "informacion_competencias = pd.get_dummies(\n",
    "    df['comp'],\n",
    "    dtype=int\n",
    " )\n",
    "\n",
    "df = pd.concat([df, informacion_competencias], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "### Features a evaluar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\n",
    "    'date',\n",
    "    'comp',\n",
    "    'round',\n",
    "    'season',\n",
    "    'team_id',\n",
    "    'full_match_report_url',\n",
    "    'team_name',\n",
    "    'opponent',\n",
    "    'opponent_id',\n",
    "    'referee',\n",
    "    'start_time'\n",
    "]\n",
    "\n",
    "features = [\n",
    "    'Passing Accuracy_against_opponent_form_avg',\n",
    "    'goals_for_opponent_form_avg',\n",
    "    'Throw Ins_favor_opponent_form_sum',\n",
    "    'Passing Accuracy_favor_opponent_form_sum',\n",
    "    'Saves_against_form_sum',\n",
    "    'Touches_favor_form_sum',\n",
    "    'Clearances_against_form_sum',\n",
    "    'Shots on Target_against_form_sum',\n",
    "    'Touches_favor_opponent_form_avg',\n",
    "    'Interceptions_against_opponent_form_avg',\n",
    "    'rest_days_opponent',\n",
    "    'xg_against_opponent_form_avg',\n",
    "    'Aerials Won_favor_opponent_form_sum',\n",
    "    'goals_against_opponent_form_sum',\n",
    "    'points_opponent_form_avg',\n",
    "    'rest_days_form_avg',\n",
    "    'Community Shield',\n",
    "    'Corners_favor_form_sum',\n",
    "    'min_wage_dollars',\n",
    "    'Sun',\n",
    "    'Possession_favor_opponent_form_avg',\n",
    "    'Clearances_against_opponent_form_avg',\n",
    "    'xg_for_opponent_form_sum',\n",
    "    'Tackles_against_form_avg',\n",
    "    'Throw Ins_against_opponent_form_sum',\n",
    "    'Passing Accuracy_against_form_avg',\n",
    "    'Goal Kicks_against_form_sum',\n",
    "    'Fouls_against_opponent_form_avg',\n",
    "    'Touches_against_form_avg',\n",
    "    'Tackles_favor_form_avg',\n",
    "    'Tackles_against_opponent_form_avg',\n",
    "    'rest_days_opponent_form_sum',\n",
    "    'Crosses_against_opponent_form_sum',\n",
    "    'FA Cup',\n",
    "    'Long Balls_favor_form_avg',\n",
    "    'Interceptions_against_form_avg',\n",
    "    'Offsides_against_opponent_form_sum',\n",
    "    'Interceptions_favor_opponent_form_avg',\n",
    "    'Throw Ins_favor_form_sum',\n",
    "    'goals_against_form_sum',\n",
    "    'goals_for_opponent_form_sum',\n",
    "    'opp_squad_size',\n",
    "    'points_form_sum',\n",
    "    'Europa Lg',\n",
    "    'Offsides_favor_opponent_form_sum',\n",
    "    'Corners_favor_opponent_form_sum',\n",
    "    'age_min',\n",
    "    'min_wage_dollars_diff',\n",
    "    'Passing Accuracy_favor_form_sum',\n",
    "    'Tackles_favor_opponent_form_sum',\n",
    "    'Possession_favor_opponent_form_sum',\n",
    "    'total_wage_bill_dollars_diff',\n",
    "    'Crosses_against_opponent_form_avg',\n",
    "    'squad_size',\n",
    "    'Offsides_against_form_avg',\n",
    "    'xg_against_form_avg',\n",
    "    'Aerials Won_favor_form_avg',\n",
    "    'rest_days_opponent_form_avg',\n",
    "    'points_opponent_form_sum',\n",
    "    'squad_size_diff',\n",
    "    'rest_days_form_sum',\n",
    "    'opp_min_wage_dollars',\n",
    "    'Corners_against_opponent_form_avg',\n",
    "    'Offsides_against_opponent_form_avg',\n",
    "    'Saves_favor_form_sum',\n",
    "    'Shots on Target_against_opponent_form_avg',\n",
    "    'Offsides_favor_form_sum',\n",
    "    'Passing Accuracy_favor_form_avg',\n",
    "    'Shots on Target_favor_form_avg',\n",
    "    'Fouls_against_form_avg',\n",
    "    'Aerials Won_against_opponent_form_avg',\n",
    "    'Long Balls_against_form_avg',\n",
    "    'opp_age_min',\n",
    "    'Clearances_favor_opponent_form_sum',\n",
    "    'EFL Cup',\n",
    "    'Touches_against_opponent_form_avg',\n",
    "    'total_wage_bill_dollars',\n",
    "    'FA Community Shield',\n",
    "    'Tackles_favor_form_sum',\n",
    "    'Offsides_favor_form_avg',\n",
    "    'goals_against_form_avg',\n",
    "    'goals_against_opponent_form_avg',\n",
    "    'Possession_against_opponent_form_avg',\n",
    "    'Throw Ins_favor_opponent_form_avg',\n",
    "    'Tackles_against_form_sum',\n",
    "    'Possession_favor_form_avg',\n",
    "    'Long Balls_favor_form_sum',\n",
    "    'Crosses_favor_form_sum',\n",
    "    'Touches_against_form_sum',\n",
    "    'Shots on Target_favor_form_sum',\n",
    "    'rest_days',\n",
    "    'Clearances_favor_form_sum',\n",
    "    'Corners_against_opponent_form_sum',\n",
    "    'Saves_against_form_avg',\n",
    "    'opp_total_wage_bill_dollars',\n",
    "    'Touches_favor_opponent_form_sum',\n",
    "    'Tackles_favor_opponent_form_avg',\n",
    "    'age_mean_diff',\n",
    "    'Possession_against_form_avg',\n",
    "    'age_max',\n",
    "    'Long Balls_favor_opponent_form_sum',\n",
    "    'Shots on Target_favor_opponent_form_sum',\n",
    "    'Premier League',\n",
    "    'Long Balls_against_opponent_form_avg',\n",
    "    'Clearances_against_form_avg',\n",
    "    'xg_against_form_sum',\n",
    "    'Fouls_favor_form_sum',\n",
    "    'Goal Kicks_favor_form_avg',\n",
    "    'Offsides_against_form_sum',\n",
    "    'opp_max_wage_dollars',\n",
    "    'Saves_favor_form_avg',\n",
    "    'Passing Accuracy_favor_opponent_form_avg',\n",
    "    'Goal Kicks_favor_opponent_form_sum',\n",
    "    'Throw Ins_against_form_avg',\n",
    "    'xg_for_form_sum',\n",
    "    'Aerials Won_against_form_sum',\n",
    "    'Tackles_against_opponent_form_sum',\n",
    "    'goals_for_form_avg',\n",
    "    'Shots on Target_favor_opponent_form_avg',\n",
    "    'Interceptions_against_form_sum',\n",
    "    'Corners_favor_form_avg',\n",
    "    'Crosses_favor_opponent_form_sum',\n",
    "    'Sat',\n",
    "    'opp_age_mean',\n",
    "    'goals_for_form_sum',\n",
    "    'Goal Kicks_against_opponent_form_avg',\n",
    "    'Passing Accuracy_against_opponent_form_sum',\n",
    "    'Possession_against_opponent_form_sum',\n",
    "    'Aerials Won_against_form_avg',\n",
    "    'max_wage_dollars_diff',\n",
    "    'Throw Ins_against_form_sum',\n",
    "    'Fouls_favor_opponent_form_avg',\n",
    "    'age_mean',\n",
    "    'age_max_diff',\n",
    "    'Saves_against_opponent_form_avg',\n",
    "    'Possession_favor_form_sum',\n",
    "    'opp_age_max',\n",
    "    'Saves_against_opponent_form_sum',\n",
    "    'Passing Accuracy_against_form_sum',\n",
    "    'Crosses_favor_opponent_form_avg',\n",
    "    'xg_for_opponent_form_avg',\n",
    "    'Interceptions_favor_form_sum',\n",
    "    'Goal Kicks_against_opponent_form_sum',\n",
    "    'Corners_against_form_avg',\n",
    "    'Interceptions_favor_form_avg',\n",
    "    'Fouls_favor_opponent_form_sum',\n",
    "    'Interceptions_favor_opponent_form_sum',\n",
    "    'Throw Ins_against_opponent_form_avg',\n",
    "    'xg_against_opponent_form_sum',\n",
    "    'Goal Kicks_favor_form_sum',\n",
    "    'Throw Ins_favor_form_avg',\n",
    "    'opp_avg_wage_dollars',\n",
    "    'Fouls_favor_form_avg',\n",
    "    'Touches_against_opponent_form_sum',\n",
    "    'max_wage_dollars',\n",
    "    'Touches_favor_form_avg',\n",
    "    'Saves_favor_opponent_form_avg',\n",
    "    'Champions Lg',\n",
    "    'Conf Lg',\n",
    "    'age_min_diff',\n",
    "    'Goal Kicks_against_form_avg',\n",
    "    'venue',\n",
    "    'Shots on Target_against_form_avg',\n",
    "    'avg_wage_dollars_diff',\n",
    "    'Fri',\n",
    "    'Goal Kicks_favor_opponent_form_avg',\n",
    "    'Offsides_favor_opponent_form_avg',\n",
    "    'Long Balls_against_opponent_form_sum',\n",
    "    'Clearances_favor_opponent_form_avg',\n",
    "    'Long Balls_against_form_sum',\n",
    "    'xg_for_form_avg',\n",
    "    'Crosses_against_form_sum',\n",
    "    'Aerials Won_favor_form_sum',\n",
    "    'Fouls_against_form_sum',\n",
    "    'Corners_against_form_sum',\n",
    "    'Clearances_against_opponent_form_sum',\n",
    "    'points_form_avg',\n",
    "    'Aerials Won_against_opponent_form_sum',\n",
    "    'Fouls_against_opponent_form_sum',\n",
    "    'Aerials Won_favor_opponent_form_avg',\n",
    "    'Saves_favor_opponent_form_sum',\n",
    "    'Clearances_favor_form_avg',\n",
    "    'Shots on Target_against_opponent_form_sum',\n",
    "    'Super Cup',\n",
    "    'Crosses_favor_form_avg',\n",
    "    'Interceptions_against_opponent_form_sum',\n",
    "    'Crosses_against_form_avg',\n",
    "    'Long Balls_favor_opponent_form_avg',\n",
    "    'avg_wage_dollars',\n",
    "    'Possession_against_form_sum',\n",
    "    'Corners_favor_opponent_form_avg',\n",
    "    'midweek']   \n",
    "\n",
    "target = [\n",
    "    'result'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['binary_w'] = df['result'].map(\n",
    "    {\n",
    "        'W':1,\n",
    "        'L':0,\n",
    "        'D':0\n",
    "    }\n",
    ")\n",
    "\n",
    "df['binary_d'] = df['result'].map(\n",
    "    {\n",
    "        'W':0,\n",
    "        'L':0,\n",
    "        'D':1\n",
    "    }\n",
    ")\n",
    "\n",
    "df['binary_l'] = df['result'].map(\n",
    "    {\n",
    "        'W':0,\n",
    "        'L':1,\n",
    "        'D':0\n",
    "    }\n",
    ")\n",
    "\n",
    "df_no_nulls = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation for ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[\n",
    "    df['season']!='2024-2025'\n",
    "    ]\n",
    "df_test = df[\n",
    "    (df['season']=='2024-2025') & \n",
    "    (df['comp']=='Premier League')\n",
    "    ]\n",
    "\n",
    "\n",
    "X_train = df_train[id_cols + features]\n",
    "y_train = df_train['result']\n",
    "\n",
    "X_test = df_test[id_cols + features]\n",
    "y_test = df_test['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training & Evaluation\n",
    "\n",
    "Train multiple machine learning models and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LightGBM and optimization libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Import LightGBM and optimization libraries\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"✓ LightGBM and optimization libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for LightGBM...\n",
      "Missing values before handling: 63822\n",
      "Missing values after handling: 0\n",
      "Target encoding: {'D': 0, 'L': 1, 'W': 2}\n",
      "Training set shape: (4758, 192)\n",
      "Test set shape: (760, 192)\n",
      "Training target distribution: [1039 1715 2004]\n",
      "✓ Data preparation completed\n"
     ]
    }
   ],
   "source": [
    "# Data preparation for LightGBM\n",
    "print(\"Preparing data for LightGBM...\")\n",
    "\n",
    "# Handle missing values by filling with median for numerical features\n",
    "print(f\"Missing values before handling: {X_train[features].isnull().sum().sum()}\")\n",
    "\n",
    "# Fill missing values\n",
    "X_train_clean = X_train[features].fillna(X_train[features].median())\n",
    "X_test_clean = X_test[features].fillna(X_train[features].median())  # Use training median for test set\n",
    "\n",
    "print(f\"Missing values after handling: {X_train_clean.isnull().sum().sum()}\")\n",
    "\n",
    "# Encode target variable for LightGBM (W=0, D=1, L=2)\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "print(f\"Target encoding: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}\")\n",
    "print(f\"Training set shape: {X_train_clean.shape}\")\n",
    "print(f\"Test set shape: {X_test_clean.shape}\")\n",
    "print(f\"Training target distribution: {np.bincount(y_train_encoded)}\")\n",
    "print(\"✓ Data preparation completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Hyperparameter tuning function created\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning function with cross-validation\n",
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna optimization\"\"\"\n",
    "    \n",
    "    # Define hyperparameter search space\n",
    "    params = {\n",
    "        'objective': 'multiclass',\n",
    "        'num_class': 3,\n",
    "        'metric': 'multi_logloss',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 10, 300),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0.0, 1.0),\n",
    "        'subsample_for_bin': trial.suggest_int('subsample_for_bin', 200000, 300000),\n",
    "        'verbose': -1,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # Cross-validation setup\n",
    "    cv_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = []\n",
    "    \n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv_folds.split(X_train_clean, y_train_encoded)):\n",
    "        X_fold_train, X_fold_val = X_train_clean.iloc[train_idx], X_train_clean.iloc[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train_encoded[train_idx], y_train_encoded[val_idx]\n",
    "        \n",
    "        # Create LightGBM datasets\n",
    "        train_data = lgb.Dataset(X_fold_train, label=y_fold_train)\n",
    "        val_data = lgb.Dataset(X_fold_val, label=y_fold_val, reference=train_data)\n",
    "        \n",
    "        # Train model\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_data,\n",
    "            valid_sets=[val_data],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)]\n",
    "        )\n",
    "        \n",
    "        # Predict and calculate accuracy\n",
    "        y_pred = model.predict(X_fold_val, num_iteration=model.best_iteration)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_pred_classes)\n",
    "        cv_scores.append(fold_accuracy)\n",
    "    \n",
    "    # Return mean CV accuracy (Optuna maximizes by default, so we return negative for minimization)\n",
    "    mean_accuracy = np.mean(cv_scores)\n",
    "    return mean_accuracy\n",
    "\n",
    "print(\"✓ Hyperparameter tuning function created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-10 08:48:09,337] A new study created in memory with name: no-name-1def24e8-416e-4b89-8f06-49664e0722ec\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting hyperparameter optimization...\n",
      "This may take several minutes depending on n_trials...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "109a42c6324e4e99b746e351947a7bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 1.01535\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.998862\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[7]\tvalid_0's multi_logloss: 1.00251\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[3]\tvalid_0's multi_logloss: 1.01119\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.998503\n",
      "[I 2025-08-10 08:48:11,858] Trial 0 finished with value: 0.527114315757849 and parameters: {'num_leaves': 118, 'learning_rate': 0.2536999076681772, 'feature_fraction': 0.839196365086843, 'bagging_fraction': 0.759195090518222, 'bagging_freq': 2, 'min_child_samples': 19, 'reg_alpha': 3.3323645788192616e-08, 'reg_lambda': 0.6245760287469893, 'max_depth': 9, 'min_split_gain': 0.7080725777960455, 'subsample_for_bin': 202058}. Best is trial 0 with value: 0.527114315757849.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 0.989131\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 0.979549\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's multi_logloss: 0.970047\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 0.979703\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 0.977912\n",
      "[I 2025-08-10 08:48:14,139] Trial 1 finished with value: 0.5500209863125061 and parameters: {'num_leaves': 292, 'learning_rate': 0.16967533607196555, 'feature_fraction': 0.5274034664069657, 'bagging_fraction': 0.5090949803242604, 'bagging_freq': 2, 'min_child_samples': 34, 'reg_alpha': 0.00052821153945323, 'reg_lambda': 7.71800699380605e-05, 'max_depth': 5, 'min_split_gain': 0.6118528947223795, 'subsample_for_bin': 213949}. Best is trial 1 with value: 0.5500209863125061.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.984391\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 0.967093\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 0.969589\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's multi_logloss: 0.9763\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 0.971984\n",
      "[I 2025-08-10 08:48:21,751] Trial 2 finished with value: 0.5453980330302468 and parameters: {'num_leaves': 95, 'learning_rate': 0.03476649150592621, 'feature_fraction': 0.6736419905302216, 'bagging_fraction': 0.8711055768358081, 'bagging_freq': 2, 'min_child_samples': 54, 'reg_alpha': 0.0021465011216654484, 'reg_lambda': 2.6185068507773707e-08, 'max_depth': 9, 'min_split_gain': 0.17052412368729153, 'subsample_for_bin': 206505}. Best is trial 1 with value: 0.5500209863125061.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 0.997994\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 0.993802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.992454\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.988706\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 0.989508\n",
      "[I 2025-08-10 08:48:24,056] Trial 3 finished with value: 0.5432956463342435 and parameters: {'num_leaves': 286, 'learning_rate': 0.26690431824362526, 'feature_fraction': 0.8850384088698766, 'bagging_fraction': 0.5827682615040224, 'bagging_freq': 1, 'min_child_samples': 70, 'reg_alpha': 9.148975058772307e-05, 'reg_lambda': 1.254134495897175e-07, 'max_depth': 7, 'min_split_gain': 0.034388521115218396, 'subsample_for_bin': 290932}. Best is trial 1 with value: 0.5500209863125061.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.980491\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 0.965099\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.964852\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 0.982277\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[32]\tvalid_0's multi_logloss: 0.975151\n",
      "[I 2025-08-10 08:48:26,219] Trial 4 finished with value: 0.5470776007563909 and parameters: {'num_leaves': 85, 'learning_rate': 0.09519754482692679, 'feature_fraction': 0.5870266456536466, 'bagging_fraction': 0.7120408127066865, 'bagging_freq': 4, 'min_child_samples': 22, 'reg_alpha': 5.324289357128436, 'reg_lambda': 0.09466630153726856, 'max_depth': 12, 'min_split_gain': 0.8948273504276488, 'subsample_for_bin': 259790}. Best is trial 1 with value: 0.5500209863125061.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[216]\tvalid_0's multi_logloss: 0.980528\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's multi_logloss: 0.966267\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.963276\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.973978\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's multi_logloss: 0.969832\n",
      "[I 2025-08-10 08:48:34,523] Trial 5 finished with value: 0.5533849817529536 and parameters: {'num_leaves': 278, 'learning_rate': 0.01351182947645082, 'feature_fraction': 0.5175897174514872, 'bagging_fraction': 0.4271363733463229, 'bagging_freq': 3, 'min_child_samples': 42, 'reg_alpha': 2.7678419414850017e-06, 'reg_lambda': 0.28749982347407854, 'max_depth': 6, 'min_split_gain': 0.28093450968738076, 'subsample_for_bin': 254270}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[10]\tvalid_0's multi_logloss: 0.999317\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 0.989896\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's multi_logloss: 0.984916\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 0.983026\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 0.977477\n",
      "[I 2025-08-10 08:48:37,148] Trial 6 finished with value: 0.5374132933930671 and parameters: {'num_leaves': 51, 'learning_rate': 0.1530883741573138, 'feature_fraction': 0.44473038620786254, 'bagging_fraction': 0.9921321619603104, 'bagging_freq': 6, 'min_child_samples': 24, 'reg_alpha': 1.1212412169964432e-08, 'reg_lambda': 0.2183498289760726, 'max_depth': 10, 'min_split_gain': 0.7290071680409873, 'subsample_for_bin': 277127}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[74]\tvalid_0's multi_logloss: 0.981481\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.96556\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[125]\tvalid_0's multi_logloss: 0.964788\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[65]\tvalid_0's multi_logloss: 0.976902\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[73]\tvalid_0's multi_logloss: 0.966726\n",
      "[I 2025-08-10 08:48:42,454] Trial 7 finished with value: 0.5481306718270905 and parameters: {'num_leaves': 31, 'learning_rate': 0.0338452204120114, 'feature_fraction': 0.4695214357150779, 'bagging_fraction': 0.9178620555253562, 'bagging_freq': 5, 'min_child_samples': 36, 'reg_alpha': 3.732717755563729e-08, 'reg_lambda': 6.292756043818863e-06, 'max_depth': 6, 'min_split_gain': 0.7296061783380641, 'subsample_for_bin': 263756}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's multi_logloss: 0.980111\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[56]\tvalid_0's multi_logloss: 0.967667\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 0.962379\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 0.976443\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's multi_logloss: 0.969806\n",
      "[I 2025-08-10 08:48:46,693] Trial 8 finished with value: 0.5529603955146728 and parameters: {'num_leaves': 268, 'learning_rate': 0.049833191601257244, 'feature_fraction': 0.471756547562981, 'bagging_fraction': 0.827946872333797, 'bagging_freq': 6, 'min_child_samples': 58, 'reg_alpha': 0.08683696167603723, 'reg_lambda': 0.0002780739892288472, 'max_depth': 8, 'min_split_gain': 0.42754101835854963, 'subsample_for_bin': 202541}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.97511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 0.971015\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's multi_logloss: 0.964137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.976943\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[246]\tvalid_0's multi_logloss: 0.973923\n",
      "[I 2025-08-10 08:48:56,981] Trial 9 finished with value: 0.5529610582403308 and parameters: {'num_leaves': 41, 'learning_rate': 0.011128194768838964, 'feature_fraction': 0.7818462467582683, 'bagging_fraction': 0.588613588645796, 'bagging_freq': 4, 'min_child_samples': 92, 'reg_alpha': 1.7523871598466864e-06, 'reg_lambda': 4.9368087974032924e-05, 'max_depth': 10, 'min_split_gain': 0.22879816549162246, 'subsample_for_bin': 207698}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's multi_logloss: 0.977084\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[408]\tvalid_0's multi_logloss: 0.970676\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[474]\tvalid_0's multi_logloss: 0.962217\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[324]\tvalid_0's multi_logloss: 0.97292\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[317]\tvalid_0's multi_logloss: 0.967805\n",
      "[I 2025-08-10 08:49:05,665] Trial 10 finished with value: 0.5508613224469598 and parameters: {'num_leaves': 202, 'learning_rate': 0.010206070557576998, 'feature_fraction': 0.9817222664727197, 'bagging_fraction': 0.4107771253688919, 'bagging_freq': 3, 'min_child_samples': 80, 'reg_alpha': 2.0957649527062313e-06, 'reg_lambda': 5.94924613627358, 'max_depth': 3, 'min_split_gain': 0.37960424342022364, 'subsample_for_bin': 228076}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.976322\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[327]\tvalid_0's multi_logloss: 0.968255\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.967597\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 0.975325\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.971842\n",
      "[I 2025-08-10 08:49:18,822] Trial 11 finished with value: 0.5506514593218992 and parameters: {'num_leaves': 188, 'learning_rate': 0.010835562498882699, 'feature_fraction': 0.721374558421294, 'bagging_fraction': 0.6055095962426541, 'bagging_freq': 4, 'min_child_samples': 100, 'reg_alpha': 4.9417276095820465e-06, 'reg_lambda': 0.007745602146756487, 'max_depth': 12, 'min_split_gain': 0.25147734302680885, 'subsample_for_bin': 236109}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.975018\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.974375\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[147]\tvalid_0's multi_logloss: 0.963644\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.97754\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[207]\tvalid_0's multi_logloss: 0.970257\n",
      "[I 2025-08-10 08:49:23,705] Trial 12 finished with value: 0.553173572268024 and parameters: {'num_leaves': 234, 'learning_rate': 0.018372875858417768, 'feature_fraction': 0.7237720640816788, 'bagging_fraction': 0.42015153096068353, 'bagging_freq': 3, 'min_child_samples': 100, 'reg_alpha': 1.970339994227758e-06, 'reg_lambda': 6.492021319831882e-06, 'max_depth': 4, 'min_split_gain': 0.2779568349059056, 'subsample_for_bin': 243308}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.980419\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.969883\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's multi_logloss: 0.955993\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.974679\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.967366\n",
      "[I 2025-08-10 08:49:28,394] Trial 13 finished with value: 0.5504400498369695 and parameters: {'num_leaves': 238, 'learning_rate': 0.02063663996551918, 'feature_fraction': 0.6216390807643536, 'bagging_fraction': 0.4078841894306851, 'bagging_freq': 3, 'min_child_samples': 40, 'reg_alpha': 2.2873103177835836e-05, 'reg_lambda': 5.385659685389981e-07, 'max_depth': 4, 'min_split_gain': 0.05642195445749476, 'subsample_for_bin': 242320}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.977481\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.975351\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.965916\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.974271\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[141]\tvalid_0's multi_logloss: 0.972463\n",
      "[I 2025-08-10 08:49:34,401] Trial 14 finished with value: 0.5489694616016754 and parameters: {'num_leaves': 225, 'learning_rate': 0.01898801839062978, 'feature_fraction': 0.7232358089629481, 'bagging_fraction': 0.4883793210012592, 'bagging_freq': 7, 'min_child_samples': 68, 'reg_alpha': 2.852196860818722e-07, 'reg_lambda': 0.0040650176778547955, 'max_depth': 5, 'min_split_gain': 0.3230881603710822, 'subsample_for_bin': 253315}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.978228\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.970908\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.956995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's multi_logloss: 0.975481\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[313]\tvalid_0's multi_logloss: 0.965656\n",
      "[I 2025-08-10 08:49:40,753] Trial 15 finished with value: 0.551282815965503 and parameters: {'num_leaves': 156, 'learning_rate': 0.019369993824877554, 'feature_fraction': 0.5638945052640644, 'bagging_fraction': 0.4919043583232473, 'bagging_freq': 3, 'min_child_samples': 5, 'reg_alpha': 0.00442604786087434, 'reg_lambda': 4.185487106539191e-06, 'max_depth': 3, 'min_split_gain': 0.4737549304289932, 'subsample_for_bin': 269851}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's multi_logloss: 0.979636\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.965171\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.966203\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's multi_logloss: 0.977034\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.969918\n",
      "[I 2025-08-10 08:49:47,067] Trial 16 finished with value: 0.5510736155661002 and parameters: {'num_leaves': 257, 'learning_rate': 0.027922411773339054, 'feature_fraction': 0.6616599001433682, 'bagging_fraction': 0.6516085768178185, 'bagging_freq': 1, 'min_child_samples': 83, 'reg_alpha': 6.939491904069986e-07, 'reg_lambda': 0.0025126494844290473, 'max_depth': 6, 'min_split_gain': 0.15738874882373133, 'subsample_for_bin': 224475}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's multi_logloss: 0.985152\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.974368\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[50]\tvalid_0's multi_logloss: 0.973484\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.980455\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.975742\n",
      "[I 2025-08-10 08:49:50,186] Trial 17 finished with value: 0.5500196608611899 and parameters: {'num_leaves': 182, 'learning_rate': 0.06808618728018409, 'feature_fraction': 0.7882452026388829, 'bagging_fraction': 0.5236120145075512, 'bagging_freq': 5, 'min_child_samples': 46, 'reg_alpha': 3.620309194593523e-05, 'reg_lambda': 8.346314881031612, 'max_depth': 5, 'min_split_gain': 0.5587459153226462, 'subsample_for_bin': 247935}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.980795\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.967097\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's multi_logloss: 0.965427\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.979001\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.97139\n",
      "[I 2025-08-10 08:50:00,164] Trial 18 finished with value: 0.5506510175047937 and parameters: {'num_leaves': 227, 'learning_rate': 0.01376319621277682, 'feature_fraction': 0.9728557298143399, 'bagging_fraction': 0.40150125313327184, 'bagging_freq': 3, 'min_child_samples': 64, 'reg_alpha': 2.553919773598308e-07, 'reg_lambda': 5.461092854569474e-06, 'max_depth': 7, 'min_split_gain': 0.32566744714125007, 'subsample_for_bin': 299385}. Best is trial 5 with value: 0.5533849817529536.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.978144\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.970207\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's multi_logloss: 0.959805\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.972494\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's multi_logloss: 0.966396\n",
      "[I 2025-08-10 08:50:05,972] Trial 19 finished with value: 0.5538024989175481 and parameters: {'num_leaves': 153, 'learning_rate': 0.01685272332263165, 'feature_fraction': 0.41032038529485937, 'bagging_fraction': 0.4538275829384247, 'bagging_freq': 5, 'min_child_samples': 78, 'reg_alpha': 0.036857067984580945, 'reg_lambda': 0.026193113052681127, 'max_depth': 4, 'min_split_gain': 0.13108350003195723, 'subsample_for_bin': 280183}. Best is trial 19 with value: 0.5538024989175481.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[36]\tvalid_0's multi_logloss: 0.979693\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 0.968095\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[69]\tvalid_0's multi_logloss: 0.957471\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.979899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's multi_logloss: 0.970185\n",
      "[I 2025-08-10 08:50:08,890] Trial 20 finished with value: 0.5510711855720206 and parameters: {'num_leaves': 137, 'learning_rate': 0.05201397494349626, 'feature_fraction': 0.41976330717518107, 'bagging_fraction': 0.5496602860968346, 'bagging_freq': 5, 'min_child_samples': 77, 'reg_alpha': 0.0922676842924885, 'reg_lambda': 0.03545177489509173, 'max_depth': 6, 'min_split_gain': 0.12960737883292628, 'subsample_for_bin': 278716}. Best is trial 19 with value: 0.5538024989175481.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.977843\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[357]\tvalid_0's multi_logloss: 0.971249\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 0.959765\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[171]\tvalid_0's multi_logloss: 0.972616\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's multi_logloss: 0.967324\n",
      "[I 2025-08-10 08:50:13,645] Trial 21 finished with value: 0.5544338555611519 and parameters: {'num_leaves': 165, 'learning_rate': 0.01522798737951118, 'feature_fraction': 0.4011434628106962, 'bagging_fraction': 0.45345685509645395, 'bagging_freq': 5, 'min_child_samples': 100, 'reg_alpha': 0.4056170072955384, 'reg_lambda': 1.1841759904500195, 'max_depth': 4, 'min_split_gain': 0.2541730736030031, 'subsample_for_bin': 285383}. Best is trial 21 with value: 0.5544338555611519.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.97586\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's multi_logloss: 0.97044\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's multi_logloss: 0.96108\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's multi_logloss: 0.972469\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.971374\n",
      "[I 2025-08-10 08:50:20,016] Trial 22 finished with value: 0.555064328570545 and parameters: {'num_leaves': 157, 'learning_rate': 0.013722590382267669, 'feature_fraction': 0.4887433236412779, 'bagging_fraction': 0.48030657072090543, 'bagging_freq': 6, 'min_child_samples': 87, 'reg_alpha': 2.6592140808761098, 'reg_lambda': 1.110891349735876, 'max_depth': 4, 'min_split_gain': 0.0138975581790165, 'subsample_for_bin': 286981}. Best is trial 22 with value: 0.555064328570545.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.976173\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.971106\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.965498\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.976753\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.971309\n",
      "[I 2025-08-10 08:50:23,996] Trial 23 finished with value: 0.558637524410395 and parameters: {'num_leaves': 159, 'learning_rate': 0.028313172914310722, 'feature_fraction': 0.4001572673828278, 'bagging_fraction': 0.47335018732867257, 'bagging_freq': 6, 'min_child_samples': 90, 'reg_alpha': 8.294667356727873, 'reg_lambda': 2.438991646607493, 'max_depth': 4, 'min_split_gain': 0.030033635030515426, 'subsample_for_bin': 287502}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.974786\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's multi_logloss: 0.970386\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 0.964565\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.974276\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.967872\n",
      "[I 2025-08-10 08:50:28,629] Trial 24 finished with value: 0.555485822089088 and parameters: {'num_leaves': 160, 'learning_rate': 0.02537690316921521, 'feature_fraction': 0.5035375608930626, 'bagging_fraction': 0.6484440415143159, 'bagging_freq': 7, 'min_child_samples': 90, 'reg_alpha': 9.250087435416571, 'reg_lambda': 1.531647074122754, 'max_depth': 3, 'min_split_gain': 0.0024389987555572396, 'subsample_for_bin': 288208}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[159]\tvalid_0's multi_logloss: 0.976324\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[259]\tvalid_0's multi_logloss: 0.969262\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.96498\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.975302\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.96736\n",
      "[I 2025-08-10 08:50:32,640] Trial 25 finished with value: 0.5521220475571933 and parameters: {'num_leaves': 125, 'learning_rate': 0.0274005103017922, 'feature_fraction': 0.5080467513107515, 'bagging_fraction': 0.6512793750063206, 'bagging_freq': 7, 'min_child_samples': 89, 'reg_alpha': 7.661463984955154, 'reg_lambda': 2.131614883885647, 'max_depth': 3, 'min_split_gain': 0.04348512434717365, 'subsample_for_bin': 299397}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[133]\tvalid_0's multi_logloss: 0.978793\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.966801\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.960532\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.97319\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's multi_logloss: 0.966369\n",
      "[I 2025-08-10 08:50:36,900] Trial 26 finished with value: 0.5540139084024778 and parameters: {'num_leaves': 97, 'learning_rate': 0.02655416144035223, 'feature_fraction': 0.4834851051177912, 'bagging_fraction': 0.7601446988508317, 'bagging_freq': 6, 'min_child_samples': 91, 'reg_alpha': 1.5228416065495445, 'reg_lambda': 1.4915445654031327, 'max_depth': 3, 'min_split_gain': 0.009670822234494409, 'subsample_for_bin': 286778}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 0.978888\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.970741\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 0.967173\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[75]\tvalid_0's multi_logloss: 0.975366\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's multi_logloss: 0.976269\n",
      "[I 2025-08-10 08:50:40,508] Trial 27 finished with value: 0.550229965803356 and parameters: {'num_leaves': 194, 'learning_rate': 0.04130215615487884, 'feature_fraction': 0.5633379874520175, 'bagging_fraction': 0.6464640146473034, 'bagging_freq': 7, 'min_child_samples': 88, 'reg_alpha': 0.8647497736937745, 'reg_lambda': 9.650554673574547, 'max_depth': 5, 'min_split_gain': 0.09987430073772248, 'subsample_for_bin': 272852}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.978116\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[198]\tvalid_0's multi_logloss: 0.969975\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.961483\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[172]\tvalid_0's multi_logloss: 0.975511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.969403\n",
      "[I 2025-08-10 08:50:47,046] Trial 28 finished with value: 0.5527531832922443 and parameters: {'num_leaves': 170, 'learning_rate': 0.023669183879390557, 'feature_fraction': 0.601828397370174, 'bagging_fraction': 0.7047868408143789, 'bagging_freq': 6, 'min_child_samples': 72, 'reg_alpha': 9.766347444733139, 'reg_lambda': 0.09493661579590652, 'max_depth': 4, 'min_split_gain': 0.08111459902075419, 'subsample_for_bin': 290649}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[35]\tvalid_0's multi_logloss: 0.984558\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[51]\tvalid_0's multi_logloss: 0.966756\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 0.969453\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[53]\tvalid_0's multi_logloss: 0.973214\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.965454\n",
      "[I 2025-08-10 08:50:49,322] Trial 29 finished with value: 0.5523336779506756 and parameters: {'num_leaves': 115, 'learning_rate': 0.07916049083807075, 'feature_fraction': 0.538870061657129, 'bagging_fraction': 0.5467487833573528, 'bagging_freq': 7, 'min_child_samples': 63, 'reg_alpha': 0.36290252961471475, 'reg_lambda': 0.7860981916765859, 'max_depth': 3, 'min_split_gain': 0.005376872039285888, 'subsample_for_bin': 294416}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[87]\tvalid_0's multi_logloss: 0.977933\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.964783\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[80]\tvalid_0's multi_logloss: 0.964374\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.973568\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 0.971309\n",
      "[I 2025-08-10 08:50:52,574] Trial 30 finished with value: 0.5535926357924874 and parameters: {'num_leaves': 68, 'learning_rate': 0.036735753557425414, 'feature_fraction': 0.44491018025637014, 'bagging_fraction': 0.7670445180084937, 'bagging_freq': 6, 'min_child_samples': 86, 'reg_alpha': 1.8726196794740495, 'reg_lambda': 0.0013212766543383707, 'max_depth': 5, 'min_split_gain': 0.9190681062341619, 'subsample_for_bin': 271123}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[185]\tvalid_0's multi_logloss: 0.979548\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[251]\tvalid_0's multi_logloss: 0.969966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[321]\tvalid_0's multi_logloss: 0.963024\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's multi_logloss: 0.970807\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.970076\n",
      "[I 2025-08-10 08:50:57,456] Trial 31 finished with value: 0.552331910682254 and parameters: {'num_leaves': 150, 'learning_rate': 0.013467851122888924, 'feature_fraction': 0.409636647530198, 'bagging_fraction': 0.4589247894053789, 'bagging_freq': 6, 'min_child_samples': 95, 'reg_alpha': 0.45301940635609567, 'reg_lambda': 1.6082426167148303, 'max_depth': 4, 'min_split_gain': 0.1812263900665967, 'subsample_for_bin': 282880}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.977086\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's multi_logloss: 0.969641\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 0.958995\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's multi_logloss: 0.973547\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.971174\n",
      "[I 2025-08-10 08:51:02,417] Trial 32 finished with value: 0.5542233297104331 and parameters: {'num_leaves': 169, 'learning_rate': 0.014954049585339291, 'feature_fraction': 0.40070200600071787, 'bagging_fraction': 0.46767565486785023, 'bagging_freq': 5, 'min_child_samples': 97, 'reg_alpha': 0.019951332360464768, 'reg_lambda': 0.6472539362845193, 'max_depth': 4, 'min_split_gain': 0.20907450246699383, 'subsample_for_bin': 286041}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's multi_logloss: 0.975119\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.969339\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[265]\tvalid_0's multi_logloss: 0.962271\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.971083\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.969479\n",
      "[I 2025-08-10 08:51:07,160] Trial 33 finished with value: 0.5552750753298165 and parameters: {'num_leaves': 125, 'learning_rate': 0.022619256637515305, 'feature_fraction': 0.4509360900001487, 'bagging_fraction': 0.5265458216935412, 'bagging_freq': 7, 'min_child_samples': 83, 'reg_alpha': 2.588138134975227, 'reg_lambda': 0.2160663785585962, 'max_depth': 3, 'min_split_gain': 0.10994807272487801, 'subsample_for_bin': 264047}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's multi_logloss: 0.9751\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's multi_logloss: 0.972752\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 0.96139\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's multi_logloss: 0.977532\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[118]\tvalid_0's multi_logloss: 0.971379\n",
      "[I 2025-08-10 08:51:10,279] Trial 34 finished with value: 0.5540125829511615 and parameters: {'num_leaves': 115, 'learning_rate': 0.03139498870388022, 'feature_fraction': 0.5065424410485526, 'bagging_fraction': 0.5306814617353826, 'bagging_freq': 7, 'min_child_samples': 83, 'reg_alpha': 2.6538488130394535, 'reg_lambda': 0.03487963639815083, 'max_depth': 3, 'min_split_gain': 0.0009049061540231228, 'subsample_for_bin': 266159}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.979555\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[163]\tvalid_0's multi_logloss: 0.969624\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[170]\tvalid_0's multi_logloss: 0.962708\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[113]\tvalid_0's multi_logloss: 0.971899\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.967443\n",
      "[I 2025-08-10 08:51:15,278] Trial 35 finished with value: 0.5512830368740557 and parameters: {'num_leaves': 136, 'learning_rate': 0.022794114251105235, 'feature_fraction': 0.45490339217796255, 'bagging_fraction': 0.6018654680149654, 'bagging_freq': 7, 'min_child_samples': 75, 'reg_alpha': 0.20105126559865705, 'reg_lambda': 0.21728544324920904, 'max_depth': 5, 'min_split_gain': 0.08529111302936163, 'subsample_for_bin': 293240}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.981152\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's multi_logloss: 0.971056\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 0.960602\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's multi_logloss: 0.97679\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.966244\n",
      "[I 2025-08-10 08:51:18,644] Trial 36 finished with value: 0.5506505756876884 and parameters: {'num_leaves': 214, 'learning_rate': 0.03912949087084635, 'feature_fraction': 0.6452567771373734, 'bagging_fraction': 0.5736903705161667, 'bagging_freq': 7, 'min_child_samples': 84, 'reg_alpha': 0.00841262138916459, 'reg_lambda': 3.80147899483338, 'max_depth': 3, 'min_split_gain': 0.11556484416306909, 'subsample_for_bin': 260653}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.978802\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.972674\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.962275\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.980137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.968233\n",
      "[I 2025-08-10 08:51:23,640] Trial 37 finished with value: 0.5527525205665863 and parameters: {'num_leaves': 89, 'learning_rate': 0.023715710126365155, 'feature_fraction': 0.5419161203264934, 'bagging_fraction': 0.5031477187052708, 'bagging_freq': 6, 'min_child_samples': 94, 'reg_alpha': 0.00048822718511646484, 'reg_lambda': 0.27380067339540465, 'max_depth': 7, 'min_split_gain': 0.17136920903061936, 'subsample_for_bin': 274277}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 0.992847\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's multi_logloss: 0.974113\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's multi_logloss: 0.974861\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's multi_logloss: 0.985957\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's multi_logloss: 0.97982\n",
      "[I 2025-08-10 08:51:25,921] Trial 38 finished with value: 0.5441337733831704 and parameters: {'num_leaves': 136, 'learning_rate': 0.13550300598535547, 'feature_fraction': 0.4927684575391456, 'bagging_fraction': 0.6356010538600337, 'bagging_freq': 7, 'min_child_samples': 52, 'reg_alpha': 2.300153831431581, 'reg_lambda': 0.011685352483025211, 'max_depth': 8, 'min_split_gain': 0.9934822022149359, 'subsample_for_bin': 289155}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.977089\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.969278\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[100]\tvalid_0's multi_logloss: 0.962927\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.974401\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.96993\n",
      "[I 2025-08-10 08:51:29,312] Trial 39 finished with value: 0.5546450441375288 and parameters: {'num_leaves': 104, 'learning_rate': 0.044051583432292166, 'feature_fraction': 0.4358756280126001, 'bagging_fraction': 0.5636547963221425, 'bagging_freq': 6, 'min_child_samples': 73, 'reg_alpha': 3.2329374591950883, 'reg_lambda': 1.2374121556845223e-08, 'max_depth': 4, 'min_split_gain': 0.6422089922261307, 'subsample_for_bin': 266021}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[34]\tvalid_0's multi_logloss: 0.98581\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 0.965606\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 0.966609\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's multi_logloss: 0.972087\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[48]\tvalid_0's multi_logloss: 0.966781\n",
      "[I 2025-08-10 08:51:32,882] Trial 40 finished with value: 0.5466585372319275 and parameters: {'num_leaves': 13, 'learning_rate': 0.06274749232000047, 'feature_fraction': 0.46241459255839146, 'bagging_fraction': 0.6762794819721005, 'bagging_freq': 6, 'min_child_samples': 29, 'reg_alpha': 0.00116997846405157, 'reg_lambda': 0.1185173618486389, 'max_depth': 6, 'min_split_gain': 0.05817351631056545, 'subsample_for_bin': 295590}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.976671\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's multi_logloss: 0.969743\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.961046\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[91]\tvalid_0's multi_logloss: 0.973801\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[95]\tvalid_0's multi_logloss: 0.967711\n",
      "[I 2025-08-10 08:51:36,066] Trial 41 finished with value: 0.5538033825517589 and parameters: {'num_leaves': 103, 'learning_rate': 0.044967357848860086, 'feature_fraction': 0.4375267511647607, 'bagging_fraction': 0.5617411879620968, 'bagging_freq': 6, 'min_child_samples': 73, 'reg_alpha': 4.237191067810367, 'reg_lambda': 3.219663379846475e-08, 'max_depth': 4, 'min_split_gain': 0.6673555236679688, 'subsample_for_bin': 265596}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.974947\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[134]\tvalid_0's multi_logloss: 0.967444\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.964084\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[92]\tvalid_0's multi_logloss: 0.974285\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[120]\tvalid_0's multi_logloss: 0.968952\n",
      "[I 2025-08-10 08:51:38,934] Trial 42 finished with value: 0.5514915745478002 and parameters: {'num_leaves': 60, 'learning_rate': 0.031242766612673945, 'feature_fraction': 0.43623993402601424, 'bagging_fraction': 0.6193756059114518, 'bagging_freq': 7, 'min_child_samples': 80, 'reg_alpha': 0.8741747446520299, 'reg_lambda': 1.3303651877285167e-08, 'max_depth': 3, 'min_split_gain': 0.7677208648987456, 'subsample_for_bin': 259420}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's multi_logloss: 0.976214\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's multi_logloss: 0.973324\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[104]\tvalid_0's multi_logloss: 0.964452\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's multi_logloss: 0.976911\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[127]\tvalid_0's multi_logloss: 0.96984\n",
      "[I 2025-08-10 08:51:41,653] Trial 43 finished with value: 0.5531724677252605 and parameters: {'num_leaves': 71, 'learning_rate': 0.04437924827336124, 'feature_fraction': 0.4889967468329815, 'bagging_fraction': 0.5077119933220264, 'bagging_freq': 6, 'min_child_samples': 88, 'reg_alpha': 9.496936844999288, 'reg_lambda': 0.000472101333212941, 'max_depth': 5, 'min_split_gain': 0.6470422425328357, 'subsample_for_bin': 281096}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.999792\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's multi_logloss: 0.979131\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 0.974421\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's multi_logloss: 0.986656\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's multi_logloss: 0.989947\n",
      "[I 2025-08-10 08:51:44,094] Trial 44 finished with value: 0.5395094946495949 and parameters: {'num_leaves': 122, 'learning_rate': 0.19605270613281417, 'feature_fraction': 0.5657602936803339, 'bagging_fraction': 0.5824849581016621, 'bagging_freq': 6, 'min_child_samples': 66, 'reg_alpha': 0.1163876519524274, 'reg_lambda': 0.49548526801150317, 'max_depth': 11, 'min_split_gain': 0.5313995285764974, 'subsample_for_bin': 276120}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's multi_logloss: 0.980733\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's multi_logloss: 0.965691\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's multi_logloss: 0.964185\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[26]\tvalid_0's multi_logloss: 0.972407\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[31]\tvalid_0's multi_logloss: 0.968198\n",
      "[I 2025-08-10 08:51:46,295] Trial 45 finished with value: 0.545815108377736 and parameters: {'num_leaves': 144, 'learning_rate': 0.10640006375986813, 'feature_fraction': 0.525738119680615, 'bagging_fraction': 0.7325471204344289, 'bagging_freq': 7, 'min_child_samples': 60, 'reg_alpha': 1.0307749008961942, 'reg_lambda': 3.187726407083845e-05, 'max_depth': 4, 'min_split_gain': 0.7876698021820814, 'subsample_for_bin': 255359}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's multi_logloss: 0.975891\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's multi_logloss: 0.969424\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[449]\tvalid_0's multi_logloss: 0.962049\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's multi_logloss: 0.971849\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[358]\tvalid_0's multi_logloss: 0.967866\n",
      "[I 2025-08-10 08:51:52,113] Trial 46 finished with value: 0.5556943597628325 and parameters: {'num_leaves': 180, 'learning_rate': 0.012437261280886154, 'feature_fraction': 0.43287718480142734, 'bagging_fraction': 0.4376533230540366, 'bagging_freq': 5, 'min_child_samples': 92, 'reg_alpha': 4.451763311055574, 'reg_lambda': 3.7024934924748857e-07, 'max_depth': 3, 'min_split_gain': 0.6104675028304211, 'subsample_for_bin': 267885}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[311]\tvalid_0's multi_logloss: 0.977103\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[349]\tvalid_0's multi_logloss: 0.96923\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[496]\tvalid_0's multi_logloss: 0.961819\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[334]\tvalid_0's multi_logloss: 0.973482\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[345]\tvalid_0's multi_logloss: 0.967814\n",
      "[I 2025-08-10 08:51:58,228] Trial 47 finished with value: 0.5531729095423659 and parameters: {'num_leaves': 204, 'learning_rate': 0.011943484433037704, 'feature_fraction': 0.4723748052457381, 'bagging_fraction': 0.43989439984384937, 'bagging_freq': 5, 'min_child_samples': 94, 'reg_alpha': 4.496183369538405, 'reg_lambda': 5.220217771952962e-07, 'max_depth': 3, 'min_split_gain': 0.5895911077654964, 'subsample_for_bin': 277138}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.976048\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's multi_logloss: 0.969262\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 0.961645\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's multi_logloss: 0.972231\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[304]\tvalid_0's multi_logloss: 0.970441\n",
      "[I 2025-08-10 08:52:05,479] Trial 48 finished with value: 0.5554838339121138 and parameters: {'num_leaves': 182, 'learning_rate': 0.01676215332223565, 'feature_fraction': 0.8650455189923021, 'bagging_fraction': 0.4780413333383594, 'bagging_freq': 4, 'min_child_samples': 82, 'reg_alpha': 0.21110292097233194, 'reg_lambda': 3.871662223119567, 'max_depth': 3, 'min_split_gain': 0.420685874307062, 'subsample_for_bin': 270285}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's multi_logloss: 0.979895\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[221]\tvalid_0's multi_logloss: 0.973694\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[236]\tvalid_0's multi_logloss: 0.965073\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 0.974038\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.972396\n",
      "[I 2025-08-10 08:52:11,010] Trial 49 finished with value: 0.5510714064805733 and parameters: {'num_leaves': 179, 'learning_rate': 0.01656849413541881, 'feature_fraction': 0.9236446561710974, 'bagging_fraction': 0.43505798208740204, 'bagging_freq': 4, 'min_child_samples': 81, 'reg_alpha': 0.03657826537009994, 'reg_lambda': 3.359266502766692, 'max_depth': 3, 'min_split_gain': 0.4197663721548277, 'subsample_for_bin': 269123}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.982402\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.968741\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.964082\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.979323\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[107]\tvalid_0's multi_logloss: 0.97327\n",
      "[I 2025-08-10 08:52:19,809] Trial 50 finished with value: 0.5487578312081931 and parameters: {'num_leaves': 195, 'learning_rate': 0.020277807989707144, 'feature_fraction': 0.8260477465171275, 'bagging_fraction': 0.8455804270122522, 'bagging_freq': 4, 'min_child_samples': 96, 'reg_alpha': 0.3286216405006744, 'reg_lambda': 3.9526849655330087, 'max_depth': 9, 'min_split_gain': 0.48127427624803865, 'subsample_for_bin': 259178}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's multi_logloss: 0.974645\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 0.970131\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[403]\tvalid_0's multi_logloss: 0.959789\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[329]\tvalid_0's multi_logloss: 0.972337\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[359]\tvalid_0's multi_logloss: 0.967469\n",
      "[I 2025-08-10 08:52:27,820] Trial 51 finished with value: 0.5521224893742986 and parameters: {'num_leaves': 163, 'learning_rate': 0.012120333353787227, 'feature_fraction': 0.6945167884306401, 'bagging_fraction': 0.479572616492271, 'bagging_freq': 4, 'min_child_samples': 92, 'reg_alpha': 0.8534365595841187, 'reg_lambda': 0.4000514143896074, 'max_depth': 3, 'min_split_gain': 0.03987503220623512, 'subsample_for_bin': 282105}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.976875\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.972583\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[295]\tvalid_0's multi_logloss: 0.966555\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.975907\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.972038\n",
      "[I 2025-08-10 08:52:34,187] Trial 52 finished with value: 0.5517003331300975 and parameters: {'num_leaves': 177, 'learning_rate': 0.016721162238974827, 'feature_fraction': 0.8712552780988995, 'bagging_fraction': 0.4865469005402595, 'bagging_freq': 5, 'min_child_samples': 86, 'reg_alpha': 5.234511039182537, 'reg_lambda': 2.325504023347153, 'max_depth': 4, 'min_split_gain': 0.07979185182817071, 'subsample_for_bin': 288458}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's multi_logloss: 0.974387\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's multi_logloss: 0.967115\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[337]\tvalid_0's multi_logloss: 0.960537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[270]\tvalid_0's multi_logloss: 0.974589\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[354]\tvalid_0's multi_logloss: 0.967568\n",
      "[I 2025-08-10 08:52:40,080] Trial 53 finished with value: 0.5542242133446439 and parameters: {'num_leaves': 207, 'learning_rate': 0.012768625161115339, 'feature_fraction': 0.43032834304758455, 'bagging_fraction': 0.5211860156746433, 'bagging_freq': 2, 'min_child_samples': 90, 'reg_alpha': 1.9561095801522779, 'reg_lambda': 0.17714306094502358, 'max_depth': 3, 'min_split_gain': 0.32773456118702377, 'subsample_for_bin': 251403}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[263]\tvalid_0's multi_logloss: 0.97858\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 0.970223\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[520]\tvalid_0's multi_logloss: 0.961803\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[331]\tvalid_0's multi_logloss: 0.971964\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's multi_logloss: 0.968672\n",
      "[I 2025-08-10 08:52:45,841] Trial 54 finished with value: 0.5531729095423659 and parameters: {'num_leaves': 160, 'learning_rate': 0.010591771750700666, 'feature_fraction': 0.46480988336931195, 'bagging_fraction': 0.4339348442750214, 'bagging_freq': 4, 'min_child_samples': 80, 'reg_alpha': 0.17246867709171557, 'reg_lambda': 1.757565356403747e-05, 'max_depth': 3, 'min_split_gain': 0.15154028492923605, 'subsample_for_bin': 269212}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[4]\tvalid_0's multi_logloss: 1.00469\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.987663\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[5]\tvalid_0's multi_logloss: 0.981202\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.993309\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[6]\tvalid_0's multi_logloss: 0.984132\n",
      "[I 2025-08-10 08:52:48,522] Trial 55 finished with value: 0.5390919774850003 and parameters: {'num_leaves': 189, 'learning_rate': 0.29866373378393146, 'feature_fraction': 0.7828763728511884, 'bagging_fraction': 0.5416874176453996, 'bagging_freq': 5, 'min_child_samples': 16, 'reg_alpha': 0.5641103936937382, 'reg_lambda': 0.0001307167981250496, 'max_depth': 4, 'min_split_gain': 0.20166429126814323, 'subsample_for_bin': 262465}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[197]\tvalid_0's multi_logloss: 0.978192\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[280]\tvalid_0's multi_logloss: 0.973942\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's multi_logloss: 0.962988\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[188]\tvalid_0's multi_logloss: 0.977664\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.977026\n",
      "[I 2025-08-10 08:52:56,410] Trial 56 finished with value: 0.5525415528987621 and parameters: {'num_leaves': 145, 'learning_rate': 0.01781020535904675, 'feature_fraction': 0.9457305160763435, 'bagging_fraction': 0.4710348678761006, 'bagging_freq': 7, 'min_child_samples': 84, 'reg_alpha': 5.5281253962823005, 'reg_lambda': 0.9212620724653875, 'max_depth': 5, 'min_split_gain': 0.3727802728280617, 'subsample_for_bin': 247153}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's multi_logloss: 0.98044\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.969966\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.963946\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.971394\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.970168\n",
      "[I 2025-08-10 08:52:59,502] Trial 57 finished with value: 0.5535924148839346 and parameters: {'num_leaves': 130, 'learning_rate': 0.02295232663438067, 'feature_fraction': 0.5011985916094296, 'bagging_fraction': 0.42274131218203814, 'bagging_freq': 6, 'min_child_samples': 97, 'reg_alpha': 0.00019458692286700833, 'reg_lambda': 1.3068011989147232e-06, 'max_depth': 3, 'min_split_gain': 0.7029292272006467, 'subsample_for_bin': 283858}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[164]\tvalid_0's multi_logloss: 0.97888\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[292]\tvalid_0's multi_logloss: 0.965614\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's multi_logloss: 0.963149\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[174]\tvalid_0's multi_logloss: 0.970501\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[256]\tvalid_0's multi_logloss: 0.966607\n",
      "[I 2025-08-10 08:53:09,332] Trial 58 finished with value: 0.5487598193851674 and parameters: {'num_leaves': 296, 'learning_rate': 0.014031987770223037, 'feature_fraction': 0.594948721674349, 'bagging_fraction': 0.972986587710847, 'bagging_freq': 4, 'min_child_samples': 69, 'reg_alpha': 0.051449906103307415, 'reg_lambda': 0.05871039371250142, 'max_depth': 4, 'min_split_gain': 0.05108821484905189, 'subsample_for_bin': 256547}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.976214\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[184]\tvalid_0's multi_logloss: 0.972924\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[257]\tvalid_0's multi_logloss: 0.963537\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[166]\tvalid_0's multi_logloss: 0.972814\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.96962\n",
      "[I 2025-08-10 08:53:14,865] Trial 59 finished with value: 0.5542222251676696 and parameters: {'num_leaves': 214, 'learning_rate': 0.021034520503013573, 'feature_fraction': 0.8193387419528545, 'bagging_fraction': 0.5018720665762224, 'bagging_freq': 5, 'min_child_samples': 77, 'reg_alpha': 1.4944095049229176, 'reg_lambda': 8.276703024898717, 'max_depth': 3, 'min_split_gain': 0.5124803840898065, 'subsample_for_bin': 275066}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[139]\tvalid_0's multi_logloss: 0.975384\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.970772\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[199]\tvalid_0's multi_logloss: 0.963635\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.976045\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[175]\tvalid_0's multi_logloss: 0.968795\n",
      "[I 2025-08-10 08:53:19,513] Trial 60 finished with value: 0.5546443814118708 and parameters: {'num_leaves': 244, 'learning_rate': 0.02658839119770077, 'feature_fraction': 0.7564532938910384, 'bagging_fraction': 0.4526396242031682, 'bagging_freq': 2, 'min_child_samples': 87, 'reg_alpha': 9.072165406175444, 'reg_lambda': 0.01214201228400684, 'max_depth': 4, 'min_split_gain': 0.12148156067348938, 'subsample_for_bin': 292667}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.976209\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[250]\tvalid_0's multi_logloss: 0.970563\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[241]\tvalid_0's multi_logloss: 0.964801\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[227]\tvalid_0's multi_logloss: 0.971874\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.971356\n",
      "[I 2025-08-10 08:53:24,340] Trial 61 finished with value: 0.551489586370826 and parameters: {'num_leaves': 104, 'learning_rate': 0.015663222784634646, 'feature_fraction': 0.42825411801421187, 'bagging_fraction': 0.5198955088198087, 'bagging_freq': 6, 'min_child_samples': 91, 'reg_alpha': 3.0790285035378524, 'reg_lambda': 1.4545182879686386e-07, 'max_depth': 4, 'min_split_gain': 0.6102620506629957, 'subsample_for_bin': 266230}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.978011\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[111]\tvalid_0's multi_logloss: 0.970596\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.963069\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.973667\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.96937\n",
      "[I 2025-08-10 08:53:27,754] Trial 62 finished with value: 0.5527538460179025 and parameters: {'num_leaves': 152, 'learning_rate': 0.03163620530367481, 'feature_fraction': 0.44413932330245465, 'bagging_fraction': 0.551918483544344, 'bagging_freq': 6, 'min_child_samples': 75, 'reg_alpha': 3.4283354730806828, 'reg_lambda': 5.27195184272917e-08, 'max_depth': 5, 'min_split_gain': 0.6480416058943889, 'subsample_for_bin': 296765}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[49]\tvalid_0's multi_logloss: 0.982489\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's multi_logloss: 0.969516\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's multi_logloss: 0.964513\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[55]\tvalid_0's multi_logloss: 0.975921\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[42]\tvalid_0's multi_logloss: 0.975916\n",
      "[I 2025-08-10 08:53:29,944] Trial 63 finished with value: 0.5525397856303405 and parameters: {'num_leaves': 177, 'learning_rate': 0.05951314126741566, 'feature_fraction': 0.47547620772590715, 'bagging_fraction': 0.48346701197036784, 'bagging_freq': 7, 'min_child_samples': 82, 'reg_alpha': 0.21017525320794722, 'reg_lambda': 1.9045779559594096e-07, 'max_depth': 3, 'min_split_gain': 0.03283071472724419, 'subsample_for_bin': 272558}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's multi_logloss: 0.980187\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[136]\tvalid_0's multi_logloss: 0.967256\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[112]\tvalid_0's multi_logloss: 0.963607\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.977234\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.972164\n",
      "[I 2025-08-10 08:53:35,062] Trial 64 finished with value: 0.5517001122215448 and parameters: {'num_leaves': 171, 'learning_rate': 0.029101876035822975, 'feature_fraction': 0.41722727278441, 'bagging_fraction': 0.7937283467519339, 'bagging_freq': 6, 'min_child_samples': 99, 'reg_alpha': 0.7862114326017802, 'reg_lambda': 2.5244003748771503e-06, 'max_depth': 10, 'min_split_gain': 0.5617814248934999, 'subsample_for_bin': 278628}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's multi_logloss: 0.98154\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.9653\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[86]\tvalid_0's multi_logloss: 0.968088\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[62]\tvalid_0's multi_logloss: 0.976316\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's multi_logloss: 0.973751\n",
      "[I 2025-08-10 08:53:37,555] Trial 65 finished with value: 0.5500196608611899 and parameters: {'num_leaves': 113, 'learning_rate': 0.035786642080836324, 'feature_fraction': 0.5155240556352282, 'bagging_fraction': 0.4001052077741105, 'bagging_freq': 5, 'min_child_samples': 86, 'reg_alpha': 2.06974266774267, 'reg_lambda': 1.3766644267474543e-08, 'max_depth': 4, 'min_split_gain': 0.7726522632300993, 'subsample_for_bin': 237446}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.977285\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[322]\tvalid_0's multi_logloss: 0.96884\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[365]\tvalid_0's multi_logloss: 0.960886\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[273]\tvalid_0's multi_logloss: 0.973064\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[239]\tvalid_0's multi_logloss: 0.968964\n",
      "[I 2025-08-10 08:53:42,226] Trial 66 finished with value: 0.5531726886338132 and parameters: {'num_leaves': 78, 'learning_rate': 0.018231567783133118, 'feature_fraction': 0.5391936868309656, 'bagging_fraction': 0.6067182016884752, 'bagging_freq': 7, 'min_child_samples': 72, 'reg_alpha': 9.986920570427799, 'reg_lambda': 6.221604130707518e-08, 'max_depth': 3, 'min_split_gain': 0.8213220093349503, 'subsample_for_bin': 263057}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's multi_logloss: 0.977629\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.967003\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[269]\tvalid_0's multi_logloss: 0.960953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[167]\tvalid_0's multi_logloss: 0.975295\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[145]\tvalid_0's multi_logloss: 0.967022\n",
      "[I 2025-08-10 08:53:46,942] Trial 67 finished with value: 0.5527516369323755 and parameters: {'num_leaves': 143, 'learning_rate': 0.021125429256652565, 'feature_fraction': 0.46044921043292325, 'bagging_fraction': 0.6674565701155091, 'bagging_freq': 5, 'min_child_samples': 93, 'reg_alpha': 4.17942157127965, 'reg_lambda': 4.401090607755937, 'max_depth': 4, 'min_split_gain': 0.708774988845349, 'subsample_for_bin': 268372}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[90]\tvalid_0's multi_logloss: 0.977563\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[117]\tvalid_0's multi_logloss: 0.968358\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.964842\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[128]\tvalid_0's multi_logloss: 0.975813\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.967804\n",
      "[I 2025-08-10 08:53:51,144] Trial 68 finished with value: 0.5521224893742986 and parameters: {'num_leaves': 158, 'learning_rate': 0.024623972926936025, 'feature_fraction': 0.40161436248524185, 'bagging_fraction': 0.5656554801680793, 'bagging_freq': 3, 'min_child_samples': 79, 'reg_alpha': 9.619318598254094e-06, 'reg_lambda': 1.8636879571560805, 'max_depth': 5, 'min_split_gain': 0.43749021336517535, 'subsample_for_bin': 290509}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's multi_logloss: 0.976574\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[408]\tvalid_0's multi_logloss: 0.968698\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[424]\tvalid_0's multi_logloss: 0.962716\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[415]\tvalid_0's multi_logloss: 0.971852\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[274]\tvalid_0's multi_logloss: 0.968663\n",
      "[I 2025-08-10 08:53:57,755] Trial 69 finished with value: 0.5527520787494808 and parameters: {'num_leaves': 130, 'learning_rate': 0.011009257684837384, 'feature_fraction': 0.4500590757779602, 'bagging_fraction': 0.5372156168092778, 'bagging_freq': 6, 'min_child_samples': 90, 'reg_alpha': 1.6036396163812405, 'reg_lambda': 0.9363127888373737, 'max_depth': 3, 'min_split_gain': 0.023728993706093812, 'subsample_for_bin': 212568}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[156]\tvalid_0's multi_logloss: 0.981864\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[214]\tvalid_0's multi_logloss: 0.971147\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[189]\tvalid_0's multi_logloss: 0.964121\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[233]\tvalid_0's multi_logloss: 0.97225\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.969125\n",
      "[I 2025-08-10 08:54:06,144] Trial 70 finished with value: 0.5531729095423659 and parameters: {'num_leaves': 196, 'learning_rate': 0.015050036190589216, 'feature_fraction': 0.6263681798801702, 'bagging_fraction': 0.45139857327953614, 'bagging_freq': 7, 'min_child_samples': 51, 'reg_alpha': 0.3103133816000918, 'reg_lambda': 0.4346522986041993, 'max_depth': 6, 'min_split_gain': 0.07569580080258498, 'subsample_for_bin': 285216}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.97809\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.966316\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.964152\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[130]\tvalid_0's multi_logloss: 0.978223\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 0.967564\n",
      "[I 2025-08-10 08:54:10,966] Trial 71 finished with value: 0.555064328570545 and parameters: {'num_leaves': 188, 'learning_rate': 0.02674024516068219, 'feature_fraction': 0.8644354235193021, 'bagging_fraction': 0.4617583195797417, 'bagging_freq': 1, 'min_child_samples': 87, 'reg_alpha': 9.825834089286237, 'reg_lambda': 0.016418596260119534, 'max_depth': 4, 'min_split_gain': 0.11711192462164492, 'subsample_for_bin': 292251}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[148]\tvalid_0's multi_logloss: 0.97389\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[218]\tvalid_0's multi_logloss: 0.969256\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[229]\tvalid_0's multi_logloss: 0.964632\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[165]\tvalid_0's multi_logloss: 0.978658\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.967654\n",
      "[I 2025-08-10 08:54:16,897] Trial 72 finished with value: 0.5529626046001997 and parameters: {'num_leaves': 184, 'learning_rate': 0.01954980789457103, 'feature_fraction': 0.8590236239592615, 'bagging_fraction': 0.4964055773006681, 'bagging_freq': 2, 'min_child_samples': 84, 'reg_alpha': 5.338813898639328, 'reg_lambda': 0.06660487628428984, 'max_depth': 4, 'min_split_gain': 0.00021412871697737944, 'subsample_for_bin': 298402}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.97427\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[150]\tvalid_0's multi_logloss: 0.967285\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's multi_logloss: 0.965228\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[101]\tvalid_0's multi_logloss: 0.975581\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.972161\n",
      "[I 2025-08-10 08:54:22,025] Trial 73 finished with value: 0.5514915745478002 and parameters: {'num_leaves': 170, 'learning_rate': 0.024937718193237632, 'feature_fraction': 0.8977343936076946, 'bagging_fraction': 0.4649085409477052, 'bagging_freq': 1, 'min_child_samples': 88, 'reg_alpha': 1.3294224462367523, 'reg_lambda': 2.9927891143690614e-07, 'max_depth': 4, 'min_split_gain': 0.1062420580261231, 'subsample_for_bin': 280387}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[94]\tvalid_0's multi_logloss: 0.974204\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.965634\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.963137\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[108]\tvalid_0's multi_logloss: 0.973222\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[93]\tvalid_0's multi_logloss: 0.966385\n",
      "[I 2025-08-10 08:54:26,270] Trial 74 finished with value: 0.5548551281711422 and parameters: {'num_leaves': 185, 'learning_rate': 0.034325204385237555, 'feature_fraction': 0.9008870610547376, 'bagging_fraction': 0.5113741121257419, 'bagging_freq': 1, 'min_child_samples': 75, 'reg_alpha': 3.018994727371241, 'reg_lambda': 0.0010361691995298462, 'max_depth': 3, 'min_split_gain': 0.0708794722425, 'subsample_for_bin': 288373}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[98]\tvalid_0's multi_logloss: 0.976459\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's multi_logloss: 0.969454\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's multi_logloss: 0.963992\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[82]\tvalid_0's multi_logloss: 0.97553\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.968772\n",
      "[I 2025-08-10 08:54:30,153] Trial 75 finished with value: 0.5472876847900043 and parameters: {'num_leaves': 216, 'learning_rate': 0.029379730137600084, 'feature_fraction': 0.923722834699747, 'bagging_fraction': 0.42594240392059834, 'bagging_freq': 1, 'min_child_samples': 77, 'reg_alpha': 0.48098002279753266, 'reg_lambda': 0.0010714054695034527, 'max_depth': 3, 'min_split_gain': 0.15074969255585197, 'subsample_for_bin': 287529}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.976076\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's multi_logloss: 0.972917\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[158]\tvalid_0's multi_logloss: 0.963659\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's multi_logloss: 0.975311\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[129]\tvalid_0's multi_logloss: 0.967969\n",
      "[I 2025-08-10 08:54:33,378] Trial 76 finished with value: 0.5544331928354939 and parameters: {'num_leaves': 190, 'learning_rate': 0.03397978183511634, 'feature_fraction': 0.843827469287867, 'bagging_fraction': 0.41362738162724594, 'bagging_freq': 1, 'min_child_samples': 97, 'reg_alpha': 5.700478559223416, 'reg_lambda': 0.023794372668123426, 'max_depth': 3, 'min_split_gain': 0.2272829223820949, 'subsample_for_bin': 292474}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.973721\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.967483\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.96431\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[181]\tvalid_0's multi_logloss: 0.976212\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.970111\n",
      "[I 2025-08-10 08:54:38,700] Trial 77 finished with value: 0.5559059901563149 and parameters: {'num_leaves': 199, 'learning_rate': 0.02139913564638859, 'feature_fraction': 0.9947923927467486, 'bagging_fraction': 0.5132530558929984, 'bagging_freq': 1, 'min_child_samples': 84, 'reg_alpha': 2.3796354608391477, 'reg_lambda': 0.003674479352448388, 'max_depth': 3, 'min_split_gain': 0.0630214501057309, 'subsample_for_bin': 289826}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[194]\tvalid_0's multi_logloss: 0.973461\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[272]\tvalid_0's multi_logloss: 0.968371\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[374]\tvalid_0's multi_logloss: 0.9625\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.978628\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[268]\tvalid_0's multi_logloss: 0.969786\n",
      "[I 2025-08-10 08:54:45,448] Trial 78 finished with value: 0.5517012167643083 and parameters: {'num_leaves': 227, 'learning_rate': 0.013968316534992408, 'feature_fraction': 0.998916049020824, 'bagging_fraction': 0.4420220653376776, 'bagging_freq': 2, 'min_child_samples': 93, 'reg_alpha': 0.5860574065583561, 'reg_lambda': 0.009496667273490588, 'max_depth': 3, 'min_split_gain': 0.2765482067538936, 'subsample_for_bin': 295771}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[105]\tvalid_0's multi_logloss: 0.978435\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[137]\tvalid_0's multi_logloss: 0.968746\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[157]\tvalid_0's multi_logloss: 0.96475\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[102]\tvalid_0's multi_logloss: 0.97822\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[121]\tvalid_0's multi_logloss: 0.968713\n",
      "[I 2025-08-10 08:54:51,345] Trial 79 finished with value: 0.5485492935344485 and parameters: {'num_leaves': 202, 'learning_rate': 0.0215038691537006, 'feature_fraction': 0.9709608214275346, 'bagging_fraction': 0.47802714809451496, 'bagging_freq': 1, 'min_child_samples': 85, 'reg_alpha': 1.0169928382373705, 'reg_lambda': 0.004931892883088958, 'max_depth': 5, 'min_split_gain': 0.10261874122329336, 'subsample_for_bin': 284071}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.974063\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.963216\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[191]\tvalid_0's multi_logloss: 0.961201\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.978173\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[143]\tvalid_0's multi_logloss: 0.969017\n",
      "[I 2025-08-10 08:54:57,188] Trial 80 finished with value: 0.5521227102828513 and parameters: {'num_leaves': 163, 'learning_rate': 0.018397690097508936, 'feature_fraction': 0.7573849241399732, 'bagging_fraction': 0.49378679784185936, 'bagging_freq': 1, 'min_child_samples': 82, 'reg_alpha': 0.015369620098513715, 'reg_lambda': 0.002219716116305157, 'max_depth': 4, 'min_split_gain': 0.1843906932278877, 'subsample_for_bin': 290854}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's multi_logloss: 0.973648\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[260]\tvalid_0's multi_logloss: 0.966771\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.962266\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's multi_logloss: 0.975262\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[142]\tvalid_0's multi_logloss: 0.969944\n",
      "[I 2025-08-10 08:55:01,573] Trial 81 finished with value: 0.553171363182497 and parameters: {'num_leaves': 185, 'learning_rate': 0.02600425534296846, 'feature_fraction': 0.9439511433821162, 'bagging_fraction': 0.46476598245209866, 'bagging_freq': 1, 'min_child_samples': 89, 'reg_alpha': 2.424312230236849, 'reg_lambda': 0.0002721464079374019, 'max_depth': 3, 'min_split_gain': 0.06890369876603325, 'subsample_for_bin': 287493}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's multi_logloss: 0.976715\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[228]\tvalid_0's multi_logloss: 0.969019\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[299]\tvalid_0's multi_logloss: 0.966294\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[179]\tvalid_0's multi_logloss: 0.977508\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[205]\tvalid_0's multi_logloss: 0.965649\n",
      "[I 2025-08-10 08:55:06,980] Trial 82 finished with value: 0.5544331928354939 and parameters: {'num_leaves': 171, 'learning_rate': 0.022274052354977904, 'feature_fraction': 0.8973329782930526, 'bagging_fraction': 0.5139091066950556, 'bagging_freq': 1, 'min_child_samples': 87, 'reg_alpha': 9.908116600714834, 'reg_lambda': 0.004059432405407423, 'max_depth': 3, 'min_split_gain': 0.036380068122424704, 'subsample_for_bin': 278765}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[288]\tvalid_0's multi_logloss: 0.975404\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[382]\tvalid_0's multi_logloss: 0.966307\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[380]\tvalid_0's multi_logloss: 0.963214\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[398]\tvalid_0's multi_logloss: 0.974258\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[401]\tvalid_0's multi_logloss: 0.967702\n",
      "[I 2025-08-10 08:55:15,774] Trial 83 finished with value: 0.553804045277417 and parameters: {'num_leaves': 150, 'learning_rate': 0.010109874162054677, 'feature_fraction': 0.8129345253480261, 'bagging_fraction': 0.5282570936210289, 'bagging_freq': 1, 'min_child_samples': 91, 'reg_alpha': 2.723772154989279, 'reg_lambda': 0.0007009607485889342, 'max_depth': 3, 'min_split_gain': 0.13663735731624338, 'subsample_for_bin': 299960}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[76]\tvalid_0's multi_logloss: 0.978406\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.967078\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[96]\tvalid_0's multi_logloss: 0.965578\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's multi_logloss: 0.974372\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[97]\tvalid_0's multi_logloss: 0.96804\n",
      "[I 2025-08-10 08:55:20,631] Trial 84 finished with value: 0.5527511951152702 and parameters: {'num_leaves': 198, 'learning_rate': 0.038900006617008494, 'feature_fraction': 0.8869108382777302, 'bagging_fraction': 0.7243228068428377, 'bagging_freq': 2, 'min_child_samples': 79, 'reg_alpha': 4.97596151885956, 'reg_lambda': 0.16085627945224645, 'max_depth': 3, 'min_split_gain': 0.054030493955056075, 'subsample_for_bin': 293352}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's multi_logloss: 0.973553\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.969752\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[110]\tvalid_0's multi_logloss: 0.966284\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[106]\tvalid_0's multi_logloss: 0.976835\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[155]\tvalid_0's multi_logloss: 0.968677\n",
      "[I 2025-08-10 08:55:24,520] Trial 85 finished with value: 0.552961720965989 and parameters: {'num_leaves': 177, 'learning_rate': 0.028094812072502126, 'feature_fraction': 0.8541557760491656, 'bagging_fraction': 0.5042431397246028, 'bagging_freq': 2, 'min_child_samples': 83, 'reg_alpha': 1.1951666084803888e-08, 'reg_lambda': 5.8024826758617465, 'max_depth': 3, 'min_split_gain': 0.10669193799303738, 'subsample_for_bin': 286582}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[160]\tvalid_0's multi_logloss: 0.975822\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[209]\tvalid_0's multi_logloss: 0.965127\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[224]\tvalid_0's multi_logloss: 0.964444\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.973997\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's multi_logloss: 0.969928\n",
      "[I 2025-08-10 08:55:32,127] Trial 86 finished with value: 0.5529628255087524 and parameters: {'num_leaves': 221, 'learning_rate': 0.017259346218405476, 'feature_fraction': 0.8044599965894379, 'bagging_fraction': 0.5883716237883496, 'bagging_freq': 1, 'min_child_samples': 100, 'reg_alpha': 1.365198168496709, 'reg_lambda': 0.00016989472558665084, 'max_depth': 4, 'min_split_gain': 0.025798861234023873, 'subsample_for_bin': 282858}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[242]\tvalid_0's multi_logloss: 0.976423\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.969785\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[364]\tvalid_0's multi_logloss: 0.966006\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's multi_logloss: 0.97566\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 0.972611\n",
      "[I 2025-08-10 08:55:39,675] Trial 87 finished with value: 0.5552735289699476 and parameters: {'num_leaves': 157, 'learning_rate': 0.012816254076426323, 'feature_fraction': 0.916393390312685, 'bagging_fraction': 0.4782749192541193, 'bagging_freq': 7, 'min_child_samples': 75, 'reg_alpha': 6.403980334202381, 'reg_lambda': 0.020691423425305895, 'max_depth': 4, 'min_split_gain': 0.08108136012290566, 'subsample_for_bin': 296898}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's multi_logloss: 0.980119\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[271]\tvalid_0's multi_logloss: 0.974909\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[369]\tvalid_0's multi_logloss: 0.966846\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[364]\tvalid_0's multi_logloss: 0.977249\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.975439\n",
      "[I 2025-08-10 08:55:47,605] Trial 88 finished with value: 0.5556952433970433 and parameters: {'num_leaves': 160, 'learning_rate': 0.012109340437884246, 'feature_fraction': 0.9609175911696892, 'bagging_fraction': 0.4446891195394679, 'bagging_freq': 7, 'min_child_samples': 95, 'reg_alpha': 6.487655856293352, 'reg_lambda': 0.021011808167798702, 'max_depth': 4, 'min_split_gain': 0.016173611297149254, 'subsample_for_bin': 297000}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.979301\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[267]\tvalid_0's multi_logloss: 0.976787\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's multi_logloss: 0.963297\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.977584\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[231]\tvalid_0's multi_logloss: 0.974392\n",
      "[I 2025-08-10 08:55:55,905] Trial 89 finished with value: 0.5519115217064744 and parameters: {'num_leaves': 140, 'learning_rate': 0.012153026668886732, 'feature_fraction': 0.9553184510026173, 'bagging_fraction': 0.41489691869452605, 'bagging_freq': 7, 'min_child_samples': 94, 'reg_alpha': 6.819643714778787, 'reg_lambda': 0.04983677315410439, 'max_depth': 8, 'min_split_gain': 0.0025910191461174462, 'subsample_for_bin': 297285}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[119]\tvalid_0's multi_logloss: 0.981967\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[161]\tvalid_0's multi_logloss: 0.975326\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's multi_logloss: 0.973456\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.98079\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[168]\tvalid_0's multi_logloss: 0.97711\n",
      "[I 2025-08-10 08:56:02,756] Trial 90 finished with value: 0.5519104171637109 and parameters: {'num_leaves': 155, 'learning_rate': 0.0129437696965945, 'feature_fraction': 0.9934967946929468, 'bagging_fraction': 0.4434853253358115, 'bagging_freq': 7, 'min_child_samples': 98, 'reg_alpha': 0.6594825854495916, 'reg_lambda': 0.3085064162777283, 'max_depth': 5, 'min_split_gain': 0.08986349225645235, 'subsample_for_bin': 295381}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 0.975676\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.972299\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[364]\tvalid_0's multi_logloss: 0.965803\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's multi_logloss: 0.977533\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[203]\tvalid_0's multi_logloss: 0.978205\n",
      "[I 2025-08-10 08:56:10,240] Trial 91 finished with value: 0.5510700810292571 and parameters: {'num_leaves': 161, 'learning_rate': 0.01589139305266099, 'feature_fraction': 0.9300215963353451, 'bagging_fraction': 0.4707447224476982, 'bagging_freq': 7, 'min_child_samples': 90, 'reg_alpha': 6.693974824580955, 'reg_lambda': 0.1104547592433454, 'max_depth': 4, 'min_split_gain': 0.025078111213307885, 'subsample_for_bin': 290231}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.981438\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's multi_logloss: 0.973481\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[371]\tvalid_0's multi_logloss: 0.966495\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's multi_logloss: 0.975409\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[230]\tvalid_0's multi_logloss: 0.974087\n",
      "[I 2025-08-10 08:56:18,198] Trial 92 finished with value: 0.5514898072793787 and parameters: {'num_leaves': 150, 'learning_rate': 0.011457873826826918, 'feature_fraction': 0.971056513184699, 'bagging_fraction': 0.4555145345982281, 'bagging_freq': 7, 'min_child_samples': 96, 'reg_alpha': 3.658009211365351, 'reg_lambda': 1.2068685016276164, 'max_depth': 4, 'min_split_gain': 0.055290149550376685, 'subsample_for_bin': 293364}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.977306\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's multi_logloss: 0.972909\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's multi_logloss: 0.962629\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[238]\tvalid_0's multi_logloss: 0.974113\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[146]\tvalid_0's multi_logloss: 0.97247\n",
      "[I 2025-08-10 08:56:25,001] Trial 93 finished with value: 0.553174234993682 and parameters: {'num_leaves': 176, 'learning_rate': 0.014627946937340406, 'feature_fraction': 0.983322486239891, 'bagging_fraction': 0.49194975613937214, 'bagging_freq': 7, 'min_child_samples': 86, 'reg_alpha': 0.0018705772918907175, 'reg_lambda': 0.02279964008140909, 'max_depth': 4, 'min_split_gain': 0.13718594948826857, 'subsample_for_bin': 228096}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[182]\tvalid_0's multi_logloss: 0.977334\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.970973\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[361]\tvalid_0's multi_logloss: 0.963112\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[262]\tvalid_0's multi_logloss: 0.975699\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[210]\tvalid_0's multi_logloss: 0.970775\n",
      "[I 2025-08-10 08:56:32,454] Trial 94 finished with value: 0.553383214484532 and parameters: {'num_leaves': 167, 'learning_rate': 0.013166471059337775, 'feature_fraction': 0.9141633503087699, 'bagging_fraction': 0.47966514766723656, 'bagging_freq': 7, 'min_child_samples': 92, 'reg_alpha': 1.64167181780348, 'reg_lambda': 0.564168065172198, 'max_depth': 4, 'min_split_gain': 0.16671253089225502, 'subsample_for_bin': 291632}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[154]\tvalid_0's multi_logloss: 0.979903\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's multi_logloss: 0.969557\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[187]\tvalid_0's multi_logloss: 0.965785\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[202]\tvalid_0's multi_logloss: 0.977149\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[140]\tvalid_0's multi_logloss: 0.972033\n",
      "[I 2025-08-10 08:56:36,903] Trial 95 finished with value: 0.5542222251676696 and parameters: {'num_leaves': 209, 'learning_rate': 0.019826681610987454, 'feature_fraction': 0.4199682731956781, 'bagging_fraction': 0.430588405250391, 'bagging_freq': 7, 'min_child_samples': 95, 'reg_alpha': 2.4707244551144854, 'reg_lambda': 0.019714911371160198, 'max_depth': 5, 'min_split_gain': 0.08947957996085693, 'subsample_for_bin': 297542}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.980035\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[222]\tvalid_0's multi_logloss: 0.97511\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[294]\tvalid_0's multi_logloss: 0.967632\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[234]\tvalid_0's multi_logloss: 0.978592\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's multi_logloss: 0.973497\n",
      "[I 2025-08-10 08:56:43,457] Trial 96 finished with value: 0.5546430559605546 and parameters: {'num_leaves': 134, 'learning_rate': 0.016368580029480405, 'feature_fraction': 0.9547289681373959, 'bagging_fraction': 0.4497869990961108, 'bagging_freq': 6, 'min_child_samples': 81, 'reg_alpha': 6.79886844518349, 'reg_lambda': 0.006291288859759889, 'max_depth': 4, 'min_split_gain': 0.020209738355761647, 'subsample_for_bin': 271578}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[297]\tvalid_0's multi_logloss: 0.974276\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[612]\tvalid_0's multi_logloss: 0.967532\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[519]\tvalid_0's multi_logloss: 0.962561\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[303]\tvalid_0's multi_logloss: 0.97612\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's multi_logloss: 0.968188\n",
      "[I 2025-08-10 08:56:52,057] Trial 97 finished with value: 0.5527520787494808 and parameters: {'num_leaves': 190, 'learning_rate': 0.01001873034054466, 'feature_fraction': 0.8770677237445986, 'bagging_fraction': 0.4677045259236163, 'bagging_freq': 3, 'min_child_samples': 84, 'reg_alpha': 1.1125251375326541, 'reg_lambda': 2.3526118476311613, 'max_depth': 3, 'min_split_gain': 0.12559600358940576, 'subsample_for_bin': 294895}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[301]\tvalid_0's multi_logloss: 0.973639\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[266]\tvalid_0's multi_logloss: 0.973617\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's multi_logloss: 0.964831\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[258]\tvalid_0's multi_logloss: 0.972608\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[208]\tvalid_0's multi_logloss: 0.971475\n",
      "[I 2025-08-10 08:56:58,973] Trial 98 finished with value: 0.5495999346110685 and parameters: {'num_leaves': 147, 'learning_rate': 0.012093141180941099, 'feature_fraction': 0.9607663674181316, 'bagging_fraction': 0.5280809602677373, 'bagging_freq': 7, 'min_child_samples': 88, 'reg_alpha': 4.159550770315295, 'reg_lambda': 0.014830968882216609, 'max_depth': 3, 'min_split_gain': 0.05412256098145567, 'subsample_for_bin': 257292}. Best is trial 23 with value: 0.558637524410395.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's multi_logloss: 0.975104\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[245]\tvalid_0's multi_logloss: 0.968297\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[323]\tvalid_0's multi_logloss: 0.964158\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[213]\tvalid_0's multi_logloss: 0.97326\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[126]\tvalid_0's multi_logloss: 0.973455\n",
      "[I 2025-08-10 08:57:06,807] Trial 99 finished with value: 0.5491799874523943 and parameters: {'num_leaves': 124, 'learning_rate': 0.01407475128437769, 'feature_fraction': 0.9383647608901624, 'bagging_fraction': 0.5512725006149968, 'bagging_freq': 6, 'min_child_samples': 76, 'reg_alpha': 0.2515177149704377, 'reg_lambda': 0.0020293810224697763, 'max_depth': 4, 'min_split_gain': 0.03774640079746556, 'subsample_for_bin': 285101}. Best is trial 23 with value: 0.558637524410395.\n",
      "\n",
      "✓ Optimization completed in 0:08:57.475857\n",
      "Best accuracy: 0.5586\n",
      "\n",
      "Best parameters:\n",
      "  num_leaves: 159\n",
      "  learning_rate: 0.028313172914310722\n",
      "  feature_fraction: 0.4001572673828278\n",
      "  bagging_fraction: 0.47335018732867257\n",
      "  bagging_freq: 6\n",
      "  min_child_samples: 90\n",
      "  reg_alpha: 8.294667356727873\n",
      "  reg_lambda: 2.438991646607493\n",
      "  max_depth: 4\n",
      "  min_split_gain: 0.030033635030515426\n",
      "  subsample_for_bin: 287502\n",
      "\n",
      "✓ Study saved to: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\models\\premier_league\\lgb_optimization_study.joblib\n"
     ]
    }
   ],
   "source": [
    "# Run hyperparameter optimization\n",
    "print(\"Starting hyperparameter optimization...\")\n",
    "print(\"This may take several minutes depending on n_trials...\")\n",
    "\n",
    "# Create study\n",
    "study = optuna.create_study(\n",
    "    direction='maximize',  # We want to maximize accuracy\n",
    "    sampler=TPESampler(seed=42)\n",
    ")\n",
    "\n",
    "# Optimize hyperparameters\n",
    "start_time = datetime.now()\n",
    "study.optimize(objective, n_trials=100, show_progress_bar=True)\n",
    "end_time = datetime.now()\n",
    "\n",
    "print(f\"\\n✓ Optimization completed in {end_time - start_time}\")\n",
    "print(f\"Best accuracy: {study.best_value:.4f}\")\n",
    "print(\"\\nBest parameters:\")\n",
    "for key, value in study.best_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Save the study for later analysis\n",
    "study_path = models_dir / 'lgb_optimization_study.joblib'\n",
    "joblib.dump(study, study_path)\n",
    "print(f\"\\n✓ Study saved to: {study_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training final model with optimized parameters...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.911990\n",
      "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.031488\n",
      "[LightGBM] [Debug] init for col-wise cost 0.000181 seconds, init for row-wise cost 0.003538 seconds\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004359 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 24422\n",
      "[LightGBM] [Info] Number of data points in the train set: 4758, number of used features: 188\n",
      "[LightGBM] [Info] Start training from score -1.521569\n",
      "[LightGBM] [Info] Start training from score -1.020414\n",
      "[LightGBM] [Info] Start training from score -0.864682\n",
      "[LightGBM] [Debug] Re-bagging, using 2264 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2242 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2223 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2189 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2234 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2214 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2255 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2186 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2298 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2260 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2217 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2285 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2237 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2286 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2247 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2320 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2246 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2197 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2267 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2265 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2236 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2222 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2224 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2225 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2278 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2276 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2227 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2270 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2261 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2237 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2231 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2307 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2267 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2276 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2248 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2313 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2289 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2277 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2180 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2177 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2193 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2181 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2300 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2217 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2256 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2171 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2221 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2212 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2302 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2231 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2305 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2275 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2194 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2264 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2238 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2220 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2262 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2213 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2252 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2208 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2198 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2264 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2298 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2315 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2282 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2261 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2269 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2233 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2290 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2275 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2297 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2175 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2210 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2293 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2257 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2228 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2283 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2264 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2260 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2268 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2247 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2316 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2219 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2282 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2282 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2255 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2272 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2175 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2195 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2221 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2199 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2261 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2254 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2226 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2226 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2206 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2269 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2213 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2242 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2233 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2238 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2281 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2258 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 6 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2316 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2193 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2184 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2306 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 15 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2268 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2290 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2280 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2249 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2236 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2291 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2270 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2215 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2231 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2311 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2256 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2299 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2245 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2284 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2217 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2228 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2233 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2241 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 7 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2246 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2333 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2303 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2229 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2292 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2243 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2244 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2237 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2232 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2278 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 14 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2259 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2270 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2240 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2205 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2317 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 13 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Debug] Re-bagging, using 2234 data to train\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 8 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 10 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 9 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 11 and depth = 4\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Debug] Trained a tree with leaves = 12 and depth = 4\n",
      "✓ Final model saved to: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\models\\premier_league\\lgb_final_model.joblib\n",
      "✓ Feature names and label encoder saved\n"
     ]
    }
   ],
   "source": [
    "# Train final model with best parameters\n",
    "print(\"Training final model with optimized parameters...\")\n",
    "\n",
    "# Get best parameters and add fixed parameters\n",
    "best_params = study.best_params.copy()\n",
    "best_params.update({\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 3,\n",
    "    'metric': 'multi_logloss',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'verbose': 3,\n",
    "    'random_state': 42\n",
    "})\n",
    "\n",
    "# Create full training dataset\n",
    "train_data = lgb.Dataset(X_train_clean, label=y_train_encoded)\n",
    "\n",
    "# Train final model\n",
    "final_model = lgb.train(\n",
    "    best_params,\n",
    "    train_data,\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "# Save the final model\n",
    "model_path = models_dir / 'lgb_final_model.joblib'\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"✓ Final model saved to: {model_path}\")\n",
    "\n",
    "# Save feature names and label encoder\n",
    "joblib.dump(features, models_dir / 'feature_names.joblib')\n",
    "joblib.dump(label_encoder, models_dir / 'label_encoder.joblib')\n",
    "print(\"✓ Feature names and label encoder saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on test set...\n",
      "==================================================\n",
      "🎯 TEST SET ACCURACY: 0.4921 (49.21%)\n",
      "Cross-validation accuracy: 0.5586 (55.86%)\n",
      "\n",
      "📊 DETAILED CLASSIFICATION REPORT:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Draw       0.47      0.05      0.09       186\n",
      "        Loss       0.49      0.65      0.56       287\n",
      "         Win       0.50      0.62      0.56       287\n",
      "\n",
      "    accuracy                           0.49       760\n",
      "   macro avg       0.49      0.44      0.40       760\n",
      "weighted avg       0.49      0.49      0.44       760\n",
      "\n",
      "\n",
      "📈 CONFUSION MATRIX:\n",
      "     Predicted\n",
      "     W    D    L\n",
      "W  179   3 105\n",
      "D   85   9  92\n",
      "L   94   7 186\n",
      "\n",
      "🎯 PER-CLASS ACCURACY:\n",
      "  Win: 0.624 (62.4%)\n",
      "  Draw: 0.048 (4.8%)\n",
      "  Loss: 0.648 (64.8%)\n",
      "\n",
      "🔍 TOP 20 MOST IMPORTANT FEATURES:\n",
      "  avg_wage_dollars_diff: 2240\n",
      "  max_wage_dollars_diff: 1406\n",
      "  total_wage_bill_dollars_diff: 1085\n",
      "  min_wage_dollars_diff: 784\n",
      "  venue: 665\n",
      "  age_mean_diff: 594\n",
      "  avg_wage_dollars: 575\n",
      "  opp_avg_wage_dollars: 553\n",
      "  Touches_favor_form_avg: 534\n",
      "  Tackles_favor_form_avg: 490\n",
      "  opp_total_wage_bill_dollars: 473\n",
      "  Tackles_against_form_avg: 460\n",
      "  age_max_diff: 453\n",
      "  Saves_favor_form_sum: 441\n",
      "  total_wage_bill_dollars: 435\n",
      "  Aerials Won_against_opponent_form_avg: 425\n",
      "  Passing Accuracy_against_form_avg: 424\n",
      "  xg_for_opponent_form_avg: 417\n",
      "  Clearances_favor_form_avg: 413\n",
      "  Tackles_favor_opponent_form_avg: 409\n",
      "\n",
      "📋 TEST SET INFO:\n",
      "  Total matches: 760\n",
      "  Wins: 287 (37.8%)\n",
      "  Draws: 186 (24.5%)\n",
      "  Losses: 287 (37.8%)\n",
      "\n",
      "✅ MODEL EVALUATION COMPLETED!\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model on test set\n",
    "print(\"Evaluating model on test set...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Make predictions on test set\n",
    "y_test_pred_proba = final_model.predict(X_test_clean, num_iteration=final_model.best_iteration)\n",
    "y_test_pred_classes = np.argmax(y_test_pred_proba, axis=1)\n",
    "\n",
    "# Convert back to original labels\n",
    "y_test_pred_labels = label_encoder.inverse_transform(y_test_pred_classes)\n",
    "y_test_true_labels = label_encoder.inverse_transform(y_test_encoded)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy = accuracy_score(y_test_encoded, y_test_pred_classes)\n",
    "\n",
    "print(f\"🎯 TEST SET ACCURACY: {test_accuracy:.4f} ({test_accuracy*100:.2f}%)\")\n",
    "print(f\"Cross-validation accuracy: {study.best_value:.4f} ({study.best_value*100:.2f}%)\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\n📊 DETAILED CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test_true_labels, y_test_pred_labels, \n",
    "                          target_names=['Draw', 'Loss', 'Win']))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(\"\\n📈 CONFUSION MATRIX:\")\n",
    "cm = confusion_matrix(y_test_true_labels, y_test_pred_labels, labels=['W', 'D', 'L'])\n",
    "print(\"     Predicted\")\n",
    "print(\"     W    D    L\")\n",
    "for i, actual in enumerate(['W', 'D', 'L']):\n",
    "    print(f\"{actual}  {cm[i][0]:3d} {cm[i][1]:3d} {cm[i][2]:3d}\")\n",
    "\n",
    "# Calculate per-class accuracies\n",
    "print(\"\\n🎯 PER-CLASS ACCURACY:\")\n",
    "for i, class_name in enumerate(['Win', 'Draw', 'Loss']):\n",
    "    class_accuracy = cm[i, i] / cm[i].sum()\n",
    "    print(f\"  {class_name}: {class_accuracy:.3f} ({class_accuracy*100:.1f}%)\")\n",
    "\n",
    "# Feature importance\n",
    "print(\"\\n🔍 TOP 20 MOST IMPORTANT FEATURES:\")\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "for i, row in feature_imp.head(20).iterrows():\n",
    "    print(f\"  {row['feature']}: {row['importance']:.0f}\")\n",
    "\n",
    "# Test set distribution\n",
    "print(f\"\\n📋 TEST SET INFO:\")\n",
    "print(f\"  Total matches: {len(y_test)}\")\n",
    "print(f\"  Wins: {sum(y_test_true_labels == 'W')} ({sum(y_test_true_labels == 'W')/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  Draws: {sum(y_test_true_labels == 'D')} ({sum(y_test_true_labels == 'D')/len(y_test)*100:.1f}%)\")\n",
    "print(f\"  Losses: {sum(y_test_true_labels == 'L')} ({sum(y_test_true_labels == 'L')/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n✅ MODEL EVALUATION COMPLETED!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Función de visualización Premier League creada (Top 6 Features + Colores Oficiales)\n"
     ]
    }
   ],
   "source": [
    "# Función de visualización para LinkedIn en español (ACTUALIZADA - Premier League)\n",
    "def crear_visualizaciones_linkedin_pl(y_test_true, y_test_pred, y_test_proba, feature_importance_df, \n",
    "                                    test_accuracy, cv_accuracy, model_name=\"LightGBM\"):\n",
    "    \"\"\"\n",
    "    Crea visualizaciones profesionales para post de LinkedIn con estilo Premier League\n",
    "    \"\"\"\n",
    "    \n",
    "    # Configurar estilo profesional\n",
    "    plt.style.use('default')\n",
    "    fig = plt.figure(figsize=(20, 16))\n",
    "    \n",
    "    # Colores oficiales de la Premier League\n",
    "    colors = ['#3D195B', '#00FF85', '#E90052', '#37003C', '#04F5FF', '#FFFFFF']\n",
    "    \n",
    "    # 1. Matriz de Confusión\n",
    "    plt.subplot(2, 3, 1)\n",
    "    cm = confusion_matrix(y_test_true, y_test_pred, labels=['W', 'D', 'L'])\n",
    "    \n",
    "    # Usar colormap personalizado Premier League\n",
    "    from matplotlib.colors import LinearSegmentedColormap\n",
    "    pl_colors = ['#FFFFFF', '#3D195B']\n",
    "    pl_cmap = LinearSegmentedColormap.from_list('premier_league', pl_colors)\n",
    "    \n",
    "    im = plt.imshow(cm, cmap=pl_cmap, aspect='auto')\n",
    "    plt.colorbar(im, shrink=0.8)\n",
    "    plt.title('Matriz de Confusión\\nVictoria - Empate - Derrota', \n",
    "              fontsize=14, fontweight='bold', pad=20, color='#37003C')\n",
    "    plt.xlabel('Predicción', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.ylabel('Resultado Real', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    \n",
    "    # Etiquetas en español\n",
    "    labels_spanish = ['Victoria', 'Empate', 'Derrota']\n",
    "    plt.xticks([0, 1, 2], labels_spanish, color='#37003C', fontweight='bold')\n",
    "    plt.yticks([0, 1, 2], labels_spanish, color='#37003C', fontweight='bold')\n",
    "    \n",
    "    # Añadir valores en las celdas\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            plt.text(j, i, f'{cm[i, j]}', \n",
    "                    ha='center', va='center', fontweight='bold',\n",
    "                    color='white' if cm[i, j] > cm.max()/2 else '#37003C', fontsize=12)\n",
    "    \n",
    "    # 2. Distribución de Probabilidades por Clase\n",
    "    plt.subplot(2, 3, 2)\n",
    "    \n",
    "    # Crear violin plot de probabilidades\n",
    "    prob_data = []\n",
    "    class_names = ['Victoria', 'Empate', 'Derrota']\n",
    "    \n",
    "    for i in range(3):\n",
    "        prob_data.append(y_test_proba[:, i])\n",
    "    \n",
    "    parts = plt.violinplot(prob_data, positions=[1, 2, 3], showmeans=True)\n",
    "    \n",
    "    violin_colors = ['#00FF85', '#E90052', '#3D195B']\n",
    "    for pc, color in zip(parts['bodies'], violin_colors):\n",
    "        pc.set_facecolor(color)\n",
    "        pc.set_alpha(0.7)\n",
    "        pc.set_edgecolor('#37003C')\n",
    "    \n",
    "    plt.xlabel('Resultado', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Probabilidad', fontsize=12, fontweight='bold')\n",
    "    plt.xticks([1, 2, 3], class_names, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Precisión por Clase\n",
    "    plt.subplot(2, 3, 3)\n",
    "    \n",
    "    # Calcular precisión por clase\n",
    "    class_accuracies = []\n",
    "    for i, class_name in enumerate(['W', 'D', 'L']):\n",
    "        if cm[i].sum() > 0:\n",
    "            acc = cm[i, i] / cm[i].sum()\n",
    "            class_accuracies.append(acc * 100)\n",
    "        else:\n",
    "            class_accuracies.append(0)\n",
    "    \n",
    "    bars = plt.bar(labels_spanish, class_accuracies, color=violin_colors, \n",
    "                   alpha=0.8, edgecolor='#37003C', linewidth=2)\n",
    "    plt.title('Precisión por Tipo de Resultado', fontsize=14, fontweight='bold', \n",
    "              pad=20, color='#37003C')\n",
    "    plt.ylabel('Precisión (%)', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar, value in zip(bars, class_accuracies):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{value:.1f}%', ha='center', va='bottom', fontweight='bold', color='#37003C')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='y', color='#37003C')\n",
    "    plt.tick_params(colors='#37003C')\n",
    "    \n",
    "    # 4. Top 6 Features (Horizontal Bar Chart) - PERSONALIZADO\n",
    "    plt.subplot(2, 3, 4)\n",
    "    top_features = feature_importance_df.head(6)  # Solo top 6\n",
    "    \n",
    "    # Nombres personalizados de variables\n",
    "    custom_feature_names = {\n",
    "        'avg_wage_dollars_diff': 'Diferencia Salarios Promedio',\n",
    "        'max_wage_dollars_diff': 'Diferencia Salario Máximo', \n",
    "        'total_wage_bill_dollars': 'Presupuesto Equipo',\n",
    "        'min_wage_dollars_diff': 'Diferencia Salarios Mínimos',\n",
    "        'venue': 'Localía',\n",
    "        'age_mean_diff': 'Diferencia de Edades en Plantilla'\n",
    "    }\n",
    "    \n",
    "    # Mapear nombres o usar nombres cortos si no están en el diccionario\n",
    "    feature_names_custom = []\n",
    "    for feat in top_features['feature']:\n",
    "        if feat in custom_feature_names:\n",
    "            feature_names_custom.append(custom_feature_names[feat])\n",
    "        else:\n",
    "            # Usar nombre corto si no está en el diccionario personalizado\n",
    "            short_name = feat.replace('_form_avg', '').replace('_opponent', ' Rival').replace('_favor', ' Favor')\n",
    "            if len(short_name) > 25:\n",
    "                short_name = short_name[:22] + '...'\n",
    "            feature_names_custom.append(short_name)\n",
    "    \n",
    "    # Gradiente de colores Premier League para las barras\n",
    "    bar_colors = ['#3D195B', '#4A2C6B', '#5A3F7B', '#6A528B', '#7A659B', '#8A78AB']\n",
    "    \n",
    "    bars = plt.barh(range(len(top_features)), top_features['importance'], \n",
    "                    color=bar_colors[:len(top_features)], alpha=0.9, edgecolor='#37003C')\n",
    "    plt.yticks(range(len(top_features)), feature_names_custom, color='#37003C', fontweight='bold')\n",
    "    plt.title('Top 6 Variables Más Importantes', fontsize=14, fontweight='bold', \n",
    "              pad=20, color='#37003C')\n",
    "    plt.xlabel('Importancia', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.grid(True, alpha=0.3, axis='x', color='#37003C')\n",
    "    plt.tick_params(colors='#37003C')\n",
    "    \n",
    "    # 5. Métricas de Rendimiento Comparativa\n",
    "    plt.subplot(2, 3, 5)\n",
    "    \n",
    "    # Baseline: predicción más frecuente\n",
    "    from collections import Counter\n",
    "    most_common = Counter(y_test_true).most_common(1)[0][0]\n",
    "    baseline_accuracy = Counter(y_test_true)[most_common] / len(y_test_true)\n",
    "    \n",
    "    metrics_names = ['Modelo\\n(Test)', 'Modelo\\n(CV)', 'Baseline\\n(Frecuente)', 'Aleatorio']\n",
    "    metrics_values = [test_accuracy, cv_accuracy, baseline_accuracy, 1/3]\n",
    "    \n",
    "    bars = plt.bar(metrics_names, [v*100 for v in metrics_values], \n",
    "                   color=['#3D195B', '#00FF85', '#E90052', '#37003C'], \n",
    "                   alpha=0.8, edgecolor='#37003C', linewidth=2)\n",
    "    plt.title('Comparación de Precisión', fontsize=14, fontweight='bold', \n",
    "              pad=20, color='#37003C')\n",
    "    plt.ylabel('Precisión (%)', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.ylim(0, 100)\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bar, value in zip(bars, metrics_values):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f'{value*100:.1f}%', ha='center', va='bottom', fontweight='bold', color='#37003C')\n",
    "    \n",
    "    plt.grid(True, alpha=0.3, axis='y', color='#37003C')\n",
    "    plt.tick_params(colors='#37003C')\n",
    "    \n",
    "    # 6. Distribución de Predicciones vs Realidad\n",
    "    plt.subplot(2, 3, 6)\n",
    "    \n",
    "    # Contar distribuciones\n",
    "    real_counts = [list(y_test_true).count(label) for label in ['W', 'D', 'L']]\n",
    "    pred_counts = [list(y_test_pred).count(label) for label in ['W', 'D', 'L']]\n",
    "    \n",
    "    x = np.arange(len(labels_spanish))\n",
    "    width = 0.35\n",
    "    \n",
    "    bars1 = plt.bar(x - width/2, real_counts, width, label='Real', \n",
    "                    color='#00FF85', alpha=0.8, edgecolor='#37003C', linewidth=2)\n",
    "    bars2 = plt.bar(x + width/2, pred_counts, width, label='Predicción', \n",
    "                    color='#E90052', alpha=0.8, edgecolor='#37003C', linewidth=2)\n",
    "    \n",
    "    plt.title('Distribución: Real vs Predicción', fontsize=14, fontweight='bold', \n",
    "              pad=20, color='#37003C')\n",
    "    plt.xlabel('Tipo de Resultado', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.ylabel('Cantidad de Partidos', fontsize=12, fontweight='bold', color='#37003C')\n",
    "    plt.xticks(x, labels_spanish, color='#37003C', fontweight='bold')\n",
    "    plt.legend(fancybox=True, shadow=True)\n",
    "    plt.grid(True, alpha=0.3, axis='y', color='#37003C')\n",
    "    plt.tick_params(colors='#37003C')\n",
    "    \n",
    "    # Añadir valores en las barras\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            plt.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                    f'{int(height)}', ha='center', va='bottom', fontweight='bold', \n",
    "                    fontsize=10, color='#37003C')\n",
    "         \n",
    "    # Fondo blanco\n",
    "    fig.patch.set_facecolor('white')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(top=0.93)\n",
    "    \n",
    "    # Guardar la imagen en alta resolución para LinkedIn\n",
    "    output_path = models_dir / 'visualizacion_linkedin_premier_league.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
    "    \n",
    "    print(f\"✅ Visualización Premier League guardada en: {output_path}\")\n",
    "    print(\"⚽ Con colores oficiales y nombres personalizados!\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "print(\"✓ Función de visualización Premier League creada (Top 6 Features + Colores Oficiales)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🎨 CREANDO VISUALIZACIONES PREMIER LEAGUE PARA LINKEDIN...\n",
      "✅ Visualización Premier League guardada en: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\models\\premier_league\\visualizacion_linkedin_premier_league.png\n",
      "⚽ Con colores oficiales y nombres personalizados!\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1600 with 7 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚽ RESUMEN PREMIER LEAGUE PARA LINKEDIN:\n",
      "🎯 Modelo: LightGBM con estilo Premier League\n",
      "📈 Precisión: 49.2% en conjunto de prueba\n",
      "📊 Validación cruzada: 55.9%\n",
      "⚽ Partidos analizados: 760 (Premier League 2024-2025)\n",
      "🏆 Variables clave: Salarios, Localía, Edades\n",
      "🎨 Colores oficiales Premier League aplicados\n",
      "📁 Imagen guardada en: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\models\\premier_league\\visualizacion_linkedin_premier_league.png\n",
      "\n",
      "📱 TEXTO SUGERIDO PARA LINKEDIN (PREMIER LEAGUE):\n",
      "\n",
      "⚽ Predicción de Resultados en Premier League usando Machine Learning 🤖\n",
      "\n",
      "Desarrollé un modelo predictivo para analizar partidos de la Premier League, enfocándome en factores económicos y estructurales de los equipos.\n",
      "\n",
      "📊 Resultados del modelo:\n",
      "✅ Precisión: 49.2% en datos de prueba\n",
      "✅ Validación cruzada: 55.9%\n",
      "✅ 760 partidos de Premier League 2024-2025\n",
      "\n",
      "🔍 Variables más predictivas:\n",
      "• Diferencia en salarios promedio entre equipos\n",
      "• Diferencia en salario máximo (estrellas del equipo)\n",
      "• Presupuesto total del equipo\n",
      "• Localía (ventaja de jugar en casa)\n",
      "• Diferencia de edades en plantilla\n",
      "\n",
      "💡 Insight clave: Los factores económicos son altamente predictivos del rendimiento en fútbol. La diferencia salarial entre equipos refleja la calidad de los jugadores y se traduce en resultados en el campo.\n",
      "\n",
      "El modelo supera significativamente las predicciones aleatorias, demostrando que el \"money talks\" también en el fútbol.\n",
      "\n",
      "#PremierLeague #MachineLearning #DataScience #Football #PredictiveAnalytics #Python #LightGBM #SportsAnalytics\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Llamar a la función de visualización PREMIER LEAGUE después de la evaluación del modelo\n",
    "print(\"\\n🎨 CREANDO VISUALIZACIONES PREMIER LEAGUE PARA LINKEDIN...\")\n",
    "\n",
    "# Preparar feature importance\n",
    "feature_imp = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importance(importance_type='gain')\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Crear las visualizaciones con estilo Premier League\n",
    "output_path_pl = crear_visualizaciones_linkedin_pl(\n",
    "    y_test_true_labels, \n",
    "    y_test_pred_labels, \n",
    "    y_test_pred_proba,\n",
    "    feature_imp,\n",
    "    test_accuracy,\n",
    "    study.best_value,\n",
    "    model_name=\"LightGBM Premier League\"\n",
    ")\n",
    "\n",
    "print(f\"\\n⚽ RESUMEN PREMIER LEAGUE PARA LINKEDIN:\")\n",
    "print(f\"🎯 Modelo: LightGBM con estilo Premier League\")\n",
    "print(f\"📈 Precisión: {test_accuracy:.1%} en conjunto de prueba\")  \n",
    "print(f\"📊 Validación cruzada: {study.best_value:.1%}\")\n",
    "print(f\"⚽ Partidos analizados: {len(y_test)} (Premier League 2024-2025)\")\n",
    "print(f\"🏆 Variables clave: Salarios, Localía, Edades\")\n",
    "print(f\"🎨 Colores oficiales Premier League aplicados\")\n",
    "print(f\"📁 Imagen guardada en: {output_path_pl}\")\n",
    "\n",
    "# Texto sugerido para LinkedIn con enfoque en variables económicas\n",
    "linkedin_text_pl = f\"\"\"\n",
    "⚽ Predicción de Resultados en Premier League usando Machine Learning 🤖\n",
    "\n",
    "Desarrollé un modelo predictivo para analizar partidos de la Premier League, enfocándome en factores económicos y estructurales de los equipos.\n",
    "\n",
    "📊 Resultados del modelo:\n",
    "✅ Precisión: {test_accuracy:.1%} en datos de prueba\n",
    "✅ Validación cruzada: {study.best_value:.1%}\n",
    "✅ {len(y_test)} partidos de Premier League 2024-2025\n",
    "\n",
    "🔍 Variables más predictivas:\n",
    "• Diferencia en salarios promedio entre equipos\n",
    "• Diferencia en salario máximo (estrellas del equipo)\n",
    "• Presupuesto total del equipo\n",
    "• Localía (ventaja de jugar en casa)\n",
    "• Diferencia de edades en plantilla\n",
    "\n",
    "💡 Insight clave: Los factores económicos son altamente predictivos del rendimiento en fútbol. La diferencia salarial entre equipos refleja la calidad de los jugadores y se traduce en resultados en el campo.\n",
    "\n",
    "El modelo supera significativamente las predicciones aleatorias, demostrando que el \"money talks\" también en el fútbol.\n",
    "\n",
    "#PremierLeague #MachineLearning #DataScience #Football #PredictiveAnalytics #Python #LightGBM #SportsAnalytics\n",
    "\"\"\"\n",
    "\n",
    "print(f\"\\n📱 TEXTO SUGERIDO PARA LINKEDIN (PREMIER LEAGUE):\")\n",
    "print(linkedin_text_pl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
