{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match Stats Data Cleaning\n",
    "\n",
    "Simple notebook to clean and join match statistics data.\n",
    "\n",
    "## Steps:\n",
    "1. Load fixtures, match_stats, and team_mapping from prod\n",
    "2. Join fixtures and match_stats via match_id\n",
    "3. Keep only essential columns\n",
    "4. Join with team mapping using team_id\n",
    "5. Filter for consistent team names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50230\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\50230\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from fuzzywuzzy import fuzz, process\n",
    "\n",
    "# Set up paths\n",
    "project_root = Path().resolve().parent.parent.parent\n",
    "data_prod_path = project_root / 'data' / 'prod' / 'raw'\n",
    "\n",
    "print(f\"Loading data from: {data_prod_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixtures loaded: (5751, 30)\n",
      "Match stats loaded: (98004, 4)\n",
      "Match stats loaded: (160, 4)\n",
      "Team mapping loaded: (27, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load fixtures\n",
    "with open(data_prod_path / 'all_competitions_fixtures_dataframe.json', 'r', encoding='utf-8') as f:\n",
    "    fixtures_data = json.load(f)\n",
    "fixtures_df = pd.DataFrame(fixtures_data)\n",
    "print(f\"Fixtures loaded: {fixtures_df.shape}\")\n",
    "\n",
    "# Load match stats  \n",
    "with open(data_prod_path / 'match_stats'/'complete_names' / 'all_competitions_match_stats.json', 'r', encoding='utf-8') as f:\n",
    "    match_stats_data = json.load(f)\n",
    "match_stats_df = pd.DataFrame(match_stats_data)\n",
    "print(f\"Match stats loaded: {match_stats_df.shape}\")\n",
    "\n",
    "with open(data_prod_path / 'match_stats'/'complete_names' / 'all_competitions_remaining_matches.json', 'r', encoding='utf-8') as f:\n",
    "    match_stats_data = json.load(f)\n",
    "match_stats_df_2 = pd.DataFrame(match_stats_data)\n",
    "print(f\"Match stats loaded: {match_stats_df_2.shape}\")\n",
    "\n",
    "# Load team mapping\n",
    "with open(data_prod_path / 'all_teams.json', 'r', encoding='utf-8') as f:\n",
    "    team_mapping_data = json.load(f)\n",
    "\n",
    "# Convert nested dict to DataFrame\n",
    "team_records = []\n",
    "for team_id, team_info in team_mapping_data.items():\n",
    "    team_records.append({\n",
    "        'team_id': team_id,\n",
    "        'team_name': team_info.get('team_name', '')\n",
    "    })\n",
    "team_mapping_df = pd.DataFrame(team_records)\n",
    "print(f\"Team mapping loaded: {team_mapping_df.shape}\")\n",
    "\n",
    "match_stats_df.rename(\n",
    "    columns= {\n",
    "        'match_id':'full_match_report_url'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Join Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_stats_df_2.rename(\n",
    "    columns= {   \n",
    "        'match_id':'full_match_report_url'\n",
    "    },\n",
    "    \n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "match_stats_df = pd.concat(\n",
    "    [\n",
    "        match_stats_df,\n",
    "        match_stats_df_2\n",
    "    ],\n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Stats Match manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_match_df = pd.pivot(\n",
    "    match_stats_df,\n",
    "    index=['full_match_report_url','team_name'],\n",
    "    columns='stat_name',\n",
    "    values='stat_value'\n",
    ").reset_index()\n",
    "\n",
    "stats_match_df = stats_match_df.sort_values(\n",
    "    by=['full_match_report_url', 'team_name']\n",
    ")\n",
    "\n",
    "stats_match_df['row_num'] = stats_match_df.sort_values(['full_match_report_url', 'team_name'], ascending=True).groupby(['full_match_report_url', 'full_match_report_url']).cumcount() + 1\n",
    "\n",
    "stats_1 = stats_match_df[stats_match_df['row_num']==1].reset_index(drop=True)\n",
    "stats_2 = stats_match_df[stats_match_df['row_num']==2].reset_index(drop=True)\n",
    "\n",
    "stats_1.drop(columns=['row_num'], inplace=True)\n",
    "stats_2.drop(columns=['row_num'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create stats on favor and Against"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_favor_1 = stats_1.copy()\n",
    "perspective_against_1 = stats_2.copy()\n",
    "\n",
    "for col in perspective_favor_1.columns:\n",
    "    if col not in ['full_match_report_url', 'team_name', 'row_num']:\n",
    "        perspective_favor_1.rename(columns={col: f'{col}_favor'},inplace=True)\n",
    "\n",
    "for col in perspective_against_1.columns:\n",
    "    if col not in ['full_match_report_url', 'team_name', 'row_num']:\n",
    "        perspective_against_1.rename(columns={col: f'{col}_against'},inplace=True)\n",
    "\n",
    "perspective_1 = perspective_favor_1.merge(\n",
    "    perspective_against_1.drop(columns=['team_name'],axis = 1),\n",
    "    on=['full_match_report_url'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "perspective_favor_2 = stats_2.copy()\n",
    "perspective_against_2 = stats_1.copy()\n",
    "\n",
    "for col in perspective_favor_2.columns:\n",
    "    if col not in ['full_match_report_url', 'team_name', 'row_num']:\n",
    "        perspective_favor_2.rename(columns={col: f'{col}_favor'},inplace=True)\n",
    "\n",
    "for col in perspective_against_2.columns:\n",
    "    if col not in ['full_match_report_url', 'team_name', 'row_num']:\n",
    "        perspective_against_2.rename(columns={col: f'{col}_against'},inplace=True)\n",
    "\n",
    "perspective_2 = perspective_favor_2.merge(\n",
    "    perspective_against_2.drop(columns=['team_name'],axis = 1),\n",
    "    on=['full_match_report_url'],\n",
    "    how='inner'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Creating Master with stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_1 = perspective_1.merge(\n",
    "    fixtures_df,\n",
    "    on=['full_match_report_url'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "master_1 = master_1[master_1['team_name_x']==master_1['team_name_y']]\n",
    "\n",
    "master_2 = perspective_2.merge(\n",
    "    fixtures_df,\n",
    "    on=['full_match_report_url'],\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "master_2 = master_2[master_2['team_name_x']==master_2['team_name_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_select = [\n",
    "    'date',\n",
    "    'comp',\n",
    "    'round',\n",
    "    'season',\n",
    "    'team_id',\n",
    "    'full_match_report_url',\n",
    "    'team_name_x',\n",
    "    'opponent',\n",
    "    'Aerials Won_favor',\n",
    "    'Clearances_favor',\n",
    "    'Corners_favor',\n",
    "    'Crosses_favor',\n",
    "    'Fouls_favor',\n",
    "    'Goal Kicks_favor',\n",
    "    'Interceptions_favor',\n",
    "    'Long Balls_favor',\n",
    "    'Offsides_favor',\n",
    "    'Passing Accuracy_favor',\n",
    "    'Possession_favor',\n",
    "    'Saves_favor',\n",
    "    'Shots on Target_favor',\n",
    "    'Tackles_favor',\n",
    "    'Throw Ins_favor',\n",
    "    'Touches_favor',\n",
    "    'Aerials Won_against',\n",
    "    'Clearances_against',\n",
    "    'Corners_against',\n",
    "    'Crosses_against',\n",
    "    'Fouls_against',\n",
    "    'Goal Kicks_against',\n",
    "    'Interceptions_against',\n",
    "    'Long Balls_against',\n",
    "    'Offsides_against',\n",
    "    'Passing Accuracy_against',\n",
    "    'Possession_against',\n",
    "    'Saves_against',\n",
    "    'Shots on Target_against',\n",
    "    'Tackles_against',\n",
    "    'Throw Ins_against',\n",
    "    'Touches_against',    \n",
    "    'venue',\n",
    "    'result',\n",
    "    'formation',\n",
    "    'referee',\n",
    "    'start_time',\n",
    "    'dayofweek',\n",
    "    'goals_for',\n",
    "    'goals_against',\n",
    "    'xg_for',\n",
    "    'xg_against',\n",
    "    'opp_formation',\n",
    "    ]\n",
    "\n",
    "master_1 = master_1[cols_select]\n",
    "master_2 = master_2[cols_select]\n",
    "\n",
    "master_1.rename(\n",
    "    columns={\n",
    "        'team_name_x': 'team_name'\n",
    "    },\n",
    "    inplace=True\n",
    ")\n",
    "\n",
    "master_2.rename(\n",
    "    columns={\n",
    "        'team_name_x': 'team_name'\n",
    "    },\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_final_v1 = pd.concat(\n",
    "    [\n",
    "        master_1,\n",
    "        master_2\n",
    "    ],\n",
    "    axis=0\n",
    ")\n",
    "\n",
    "master_final_v1['date'] = pd.to_datetime(master_final_v1['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_final_v1.sort_values(\n",
    "    by=['date', 'full_match_report_url', 'team_id'],\n",
    "    inplace=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Save Master Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving master dataset to: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\n",
      "Dataset shape: (5711, 51)\n",
      "✓ Saved JSON: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\match_stats_master_dataset.json\n",
      "✓ Saved CSV: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\match_stats_master_dataset.csv\n",
      "✓ Saved Parquet: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\match_stats_master_dataset.parquet\n",
      "✓ Saved Pickle: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\match_stats_master_dataset.pkl\n",
      "✓ Saved Excel: C:\\Users\\50230\\OneDrive\\Escritorio\\Proyectos y trabajos\\Personales\\Pronósticos Football\\data\\prod\\processed\\match_stats_master_dataset.xlsx\n",
      "\n",
      "All files saved successfully!\n",
      "Total records: 5,711\n",
      "Date range: 2019-08-04 00:00:00 to 2025-05-28 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Set up output path\n",
    "output_path = project_root / 'data' / 'prod' / 'processed'\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Saving master dataset to: {output_path}\")\n",
    "print(f\"Dataset shape: {master_final_v1.shape}\")\n",
    "\n",
    "# Save in multiple formats\n",
    "filename_base = \"match_stats_master_dataset\"\n",
    "\n",
    "# 1. JSON format\n",
    "json_file = output_path / f\"{filename_base}.json\"\n",
    "master_final_v1.to_json(json_file, orient='records', date_format='iso', indent=2)\n",
    "print(f\"✓ Saved JSON: {json_file}\")\n",
    "\n",
    "# 2. CSV format\n",
    "csv_file = output_path / f\"{filename_base}.csv\"\n",
    "master_final_v1.to_csv(csv_file, index=False)\n",
    "print(f\"✓ Saved CSV: {csv_file}\")\n",
    "\n",
    "# 3. Parquet format (efficient for large datasets)\n",
    "parquet_file = output_path / f\"{filename_base}.parquet\"\n",
    "master_final_v1.to_parquet(parquet_file, index=False)\n",
    "print(f\"✓ Saved Parquet: {parquet_file}\")\n",
    "\n",
    "# 4. Pickle format (preserves data types exactly)\n",
    "pickle_file = output_path / f\"{filename_base}.pkl\"\n",
    "master_final_v1.to_pickle(pickle_file)\n",
    "print(f\"✓ Saved Pickle: {pickle_file}\")\n",
    "\n",
    "# 5. Excel format\n",
    "excel_file = output_path / f\"{filename_base}.xlsx\"\n",
    "master_final_v1.to_excel(excel_file, index=False, sheet_name='match_stats')\n",
    "print(f\"✓ Saved Excel: {excel_file}\")\n",
    "\n",
    "print(f\"\\nAll files saved successfully!\")\n",
    "print(f\"Total records: {len(master_final_v1):,}\")\n",
    "print(f\"Date range: {master_final_v1['date'].min()} to {master_final_v1['date'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
